{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 13 â€“ Visualizations II\n",
    "\n",
    "### DATA 2201, Fall 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv(\"data/world_bank.csv\", index_col=0)\n",
    "wb = wb.rename(columns={'Antiretroviral therapy coverage: % of people living with HIV: 2015':\"HIV rate\",\n",
    "                       'Gross national income per capita, Atlas method: $: 2016':'gni'})\n",
    "wb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimate (KDE)\n",
    "\n",
    "Often, we want to identify general trends across a distribution, rather than focus on detail. Smoothing a distribution helps generalize the structure of the data and eliminate noise.\n",
    "\n",
    "### Idea for KDE Implementation \n",
    "Approximate the probability distribution that generated the data by:\n",
    "1. Place a kernel at each data point.\n",
    "2. Normalize kernels so that total area = 1.\n",
    "3. Sum all kernels together.\n",
    "\n",
    "\n",
    "## Toy KDE Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [2.2, 2.8, 3.7, 5.3, 5.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(points, bins=range(0, 10, 2), ec='w', density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some **kernels**. We will explain these formulas momentarily. We'll also define some helper functions for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, z, a):\n",
    "    # Gaussian kernel\n",
    "    return (1/np.sqrt(2*np.pi*a**2)) * np.exp((-(x - z)**2 / (2 * a**2)))\n",
    "\n",
    "def boxcar_basic(x, z, a):\n",
    "    # Boxcar kernel\n",
    "    if np.abs(x - z) <= a/2:\n",
    "        return 1/a\n",
    "    return 0\n",
    "\n",
    "def boxcar(x, z, a):\n",
    "    # Boxcar kernel\n",
    "    cond = np.abs(x - z)\n",
    "    return np.piecewise(x, [cond <= a/2, cond > a/2], [1/a, 0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kde(kernel, pts, a):\n",
    "    # Takes in a kernel, set of points, and alpha\n",
    "    # Returns the KDE as a function\n",
    "    def f(x):\n",
    "        output = 0\n",
    "        for pt in pts:\n",
    "            output += kernel(x, pt, a)\n",
    "        return output / len(pts) # Normalization factor\n",
    "    return f\n",
    "\n",
    "def plot_kde(kernel, pts, a):\n",
    "    # Calls create_kde and plots the corresponding KDE\n",
    "    f = create_kde(kernel, pts, a)\n",
    "    x = np.linspace(min(pts) - 5, max(pts) + 5, 1000)\n",
    "    y = [f(xi) for xi in x]\n",
    "    plt.plot(x, y);\n",
    "    \n",
    "def plot_separate_kernels(kernel, pts, a, norm=False):\n",
    "    # Plots individual kernels, which are then summed to create the KDE\n",
    "    x = np.linspace(min(pts) - 5, max(pts) + 5, 1000)\n",
    "    for pt in pts:\n",
    "        y = kernel(x, pt, a)\n",
    "        if norm:\n",
    "            y /= len(pts)\n",
    "        plt.plot(x, y)\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our five points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "sns.rugplot(points, height=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Place a kernel at each point\n",
    "\n",
    "We'll start with the Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "plot_separate_kernels(gaussian, points, a=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Normalize kernels so that total area is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "plot_separate_kernels(gaussian, points, a=1, norm=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sum all kernels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "plot_kde(gaussian, points, a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(points, bw_method=0.65)  # Magic value!\n",
    "sns.histplot(points, stat='density', bins=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get a very similar result in a single call by requesting the KDE be added to the histogram, with `kde=True` and some extra keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(points, bins=2, kde=True, stat='density', \n",
    "             kde_kws=dict(cut=4, bw_method=0.65));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(points)\n",
    "sns.histplot(points, stat='density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "\n",
    "**Gaussian**\n",
    "\n",
    "$$K_{\\alpha}(x, x_i) = \\frac{1}{\\sqrt{2 \\pi \\alpha^2}} e^{-\\frac{(x - x_i)^2}{2\\alpha^2}}$$\n",
    "\n",
    "\n",
    "**Boxcar**\n",
    "\n",
    "\n",
    "$$K_{\\alpha}(x, x_i) = \\begin {cases}\n",
    "\t\t\t\\frac{1}{\\alpha}, \\: \\: \\: |x - x_i| \\leq \\frac{\\alpha}{2}\\\\\n",
    "\t\t\t0, \\: \\: \\: \\text{else}\n",
    "\t\t\t\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title(r'KDE of toy data with Gaussian kernel and $\\alpha$ = 1')\n",
    "plot_kde(gaussian, points, a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-3, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.title(r'KDE of toy data with Boxcar kernel and $\\alpha$ = 1')\n",
    "plot_kde(boxcar, points, a=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of bandwidth hyperparameter $\\alpha$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = wb['HIV rate'].dropna()\n",
    "ax = sns.histplot(vals)\n",
    "sns.rugplot(vals, color='orange', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.ylim(0, 0.25)\n",
    "plt.xlim(-1, 100)\n",
    "plt.title(r'KDE of tips with Gaussian kernel and $\\alpha$ = 0.1')\n",
    "plot_kde(gaussian, vals, a=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.ylim(0, 0.05)\n",
    "plt.xlim(-1, 100)\n",
    "plt.title(r'KDE of tips with Gaussian kernel and $\\alpha$ = 1')\n",
    "plot_kde(gaussian, vals, a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.ylim(0, 0.04)\n",
    "plt.xlim(-1, 100)\n",
    "plt.title(r'KDE of tips with Gaussian kernel and $\\alpha$ = 2')\n",
    "plot_kde(gaussian, vals, a=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.ylim(0, 0.04)\n",
    "plt.xlim(-1, 100)\n",
    "plt.title(r'KDE of tips with Gaussian kernel and $\\alpha$ = 10')\n",
    "plot_kde(gaussian, vals, a=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE Formula\n",
    "\n",
    "$$f_{\\alpha}(x) = \\sum_{i = 1}^n \\frac{1}{n} \\cdot K_{\\alpha}(x, x_i) =  \\frac{1}{n} \\sum_{i = 1}^n K_{\\alpha}(x, x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Distributions - Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving into `displot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn [documentation](https://seaborn.pydata.org/generated/seaborn.displot.html) for `sns.displot` lets you specify the `kind` of plot.\n",
    "\n",
    "When plotting a histogram,  you can pass in `histplot` ([link](https://seaborn.pydata.org/generated/seaborn.histplot.html#seaborn.histplot)) parameters to `displot` to specify histogram-specific features.\n",
    "\n",
    "For example, `stat=density` normalizes the histogram such that the area under the histogram is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=wb, \n",
    "            x=\"gni\", \n",
    "            kind=\"hist\", \n",
    "            stat=\"density\") # default: stat=count and density integrates to 1\n",
    "plt.title(\"Distribution of gross national income per capita\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean to specify `kind=kde`? We will explore this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(data=wb, \n",
    "            x=\"gni\", \n",
    "            kind='kde')\n",
    "plt.title(\"Distribution of gross national income per capita\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=wb, \n",
    "            x=\"gni\", \n",
    "            kind='ecdf')\n",
    "plt.title(\"Cumulative Distribution of gross national income per capita\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots\n",
    "\n",
    "Scatter plots are used to visualize the **relationship** between two **quantitative continuous variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(wb['per capita: % growth: 2016'], \n",
    "            wb['Adult literacy rate: Female: % ages 15 and older: 2005-14'])\n",
    "plt.xlabel(\"% growth per capita\")\n",
    "plt.ylabel(\"Female adult literacy rate\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "                y='Adult literacy rate: Female: % ages 15 and older: 2005-14', \n",
    "                hue=\"Continent\")\n",
    "plt.xlabel(\"% growth per capita\")\n",
    "plt.ylabel(\"Female adult literacy rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above suffer from **overplotting** â€“ many scatter points are stacked on top of one another (particularly in the upper right region of the plot). \n",
    "\n",
    "**Jittering** is a processed used to address overplotting. A small amount of random noise is added to the x and y values of all datapoints. \n",
    "\n",
    "Decreasing the size of each scatter point using the `s` parameter of `plt.scatter` also helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_x_noise = np.random.uniform(-1, 1, len(wb))\n",
    "random_y_noise = np.random.uniform(-5, 5, len(wb))\n",
    "\n",
    "plt.scatter(wb['per capita: % growth: 2016']+random_x_noise, \\\n",
    "            wb['Adult literacy rate: Female: % ages 15 and older: 2005-14']+random_y_noise, s=15)\n",
    "\n",
    "plt.xlabel(\"% growth per capita (jittered)\")\n",
    "plt.ylabel(\"Female adult literacy rate (jittered)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "           y='Adult literacy rate: Female: % ages 15 and older: 2005-14');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "              y='Adult literacy rate: Female: % ages 15 and older: 2005-14');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hex Plots\n",
    "\n",
    "Rather than plot individual datapoints, plot the *density* of how datapoints are distributed in 2D. A darker hexagon means that more datapoints lie in that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "              y='Adult literacy rate: Female: % ages 15 and older: 2005-14',\n",
    "              kind='hex');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Plots\n",
    "\n",
    "Contour plots are similar to topographic maps. Contour lines of the same color have the same *density* of datapoints. The region with the darkest color contains the most datapoints of all regions.We can think of a contour plot as the 2D equivalent of a KDE curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "              y='Adult literacy rate: Female: % ages 15 and older: 2005-14', \n",
    "            fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=wb, x='per capita: % growth: 2016', \\\n",
    "              y='Adult literacy rate: Female: % ages 15 and older: 2005-14',\n",
    "              kind='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformations\n",
    "\n",
    "Often, our reason for visualizing relationships like we did above is beause we then want to *model* these relationships. We will start talking about the theory and math underlying modeling processes next week.\n",
    "\n",
    "We will focus a lot on **linear modeling** in DATA 2201. This means that it is often helpful to transform and **linearize** our data such that it shows roughly a linear relationship. There are a few reasons for this:\n",
    "* Transforming data makes visualizations easier to interpret\n",
    "* Linear relationships are straightforward to understand â€“ we have ideas of what slopes and intercepts mean\n",
    "* Later on in the course, the ability to linearize data will help us make more effective models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data cleaning to help with the next example\n",
    "\n",
    "df = pd.DataFrame(index=wb.index)\n",
    "df['lit'] = wb['Adult literacy rate: Female: % ages 15 and older: 2005-14'] \\\n",
    "            + wb[\"Adult literacy rate: Male: % ages 15 and older: 2005-14\"]\n",
    "df['inc'] = wb['gni']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "plt.scatter(df[\"inc\"], df[\"lit\"])\n",
    "plt.xlabel(\"Gross national income per capita\")\n",
    "plt.ylabel(\"Adult literacy rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is making this plot non-linear?\n",
    "* There are a few extremely large values for gross national income that are distoring the horizontal scale of the plot. If we rescaled the x-values such that these large values become proportionally smaller, the plot would be more linear\n",
    "* There are too many large values of adult literacy rate all clumped together at the top of the plot. If we rescaled the y-axis such that large values of y are more spread out, the plot would be more linear\n",
    "\n",
    "First, we can transform the x-values such that very large values of x become smaller. This can be achieved by performing a **log transformation** of the gross national income data. When we take the logarithm of a large number, this number becomes proportionally much smaller relative to its original value. When we take the log of a small number, the number does not change very significantly relative to its starting value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log compute the natural (base e) logarithm\n",
    "plt.scatter(np.log(df[\"inc\"]), df[\"lit\"])\n",
    "plt.xlabel(\"Log(gross national income per capita)\")\n",
    "plt.ylabel(\"Adult literacy rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, the relationship is starting to look more linear! Now, we'll address the vertical scaling. \n",
    "\n",
    "To reduce the clumping of datapoints near the top of the plot, we want to spread out large values of y without substantially changing small values of y. We can do this by applying a **power transformation** â€“ that is, by raising the y-values to a power. Below, we raise all y-values to the power of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df[\"inc\"]), df[\"lit\"]**4)\n",
    "plt.xlabel(\"Log(gross national income per capita)\")\n",
    "plt.ylabel(\"Adult literacy rate (4th power)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transformed variables now seem to follow a linear relationship! \n",
    "\n",
    "$$y^4 = m(\\log{x}) + b$$\n",
    "\n",
    "We can use this fact to uncover new information about the original, untransformed variables. \n",
    "\n",
    "$$y = [m(\\log{x}) + b]^{1/4}$$\n",
    "\n",
    "In the cell below, we first fit a regression line to the transformed data to find values for the slope ($m$) and intercept ($b$). Then, we plug these values into the relationship we derived for the *untransformed* variables. We find a mathematical relationship relating the gross national income and the adult literacy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below fits a linear regression model. We'll discuss it at length in a future lecture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(np.log(df[[\"inc\"]]), df[\"lit\"]**4)\n",
    "m, b = model.coef_[0], model.intercept_\n",
    "\n",
    "print(f\"The slope, m, of the transformed data is: {m}\")\n",
    "print(f\"The intercept, b, of the transformed data is: {b}\")\n",
    "\n",
    "df = df.sort_values(\"inc\")\n",
    "plt.scatter(np.log(df[\"inc\"]), df[\"lit\"]**4, label=\"Transformed data\")\n",
    "plt.plot(np.log(df[\"inc\"]), m*np.log(df[\"inc\"])+b, c=\"red\", label=\"Linear regression\")\n",
    "plt.xlabel(\"Log(gross national income per capita)\")\n",
    "plt.ylabel(\"Adult literacy rate (4th power)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, plug the values for m and b into the relationship between the untransformed x and y\n",
    "plt.scatter(df[\"inc\"], df[\"lit\"], label=\"Untransformed data\")\n",
    "plt.plot(df[\"inc\"], (m*np.log(df[\"inc\"])+b)**(1/4), c=\"red\", label=\"Modeled relationship\")\n",
    "plt.xlabel(\"Gross national income per capita\")\n",
    "plt.ylabel(\"Adult literacy rate\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been able to find a fairly close approximation for the relationship between the original variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Theory of Visualization\n",
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf = pd.DataFrame(dict(Cancer=[2007371, 935573], \n",
    "                         Abortion=[289750, 327000]), \n",
    "                    index=pd.Series([2006, 2013], \n",
    "                    name=\"Year\"))\n",
    "ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=ppdf, markers=True)\n",
    "ax.set_title(\"Planned Parenthood Procedures\")\n",
    "ax.set_xticks([2006, 2013])\n",
    "ax.set_ylabel(\"Service count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the relative change between the two years..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_change = 100*(ppdf.loc[2013] - ppdf.loc[2006])/ppdf.loc[2006]\n",
    "rel_change.name = \"Percent Change\"\n",
    "rel_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=rel_change.index, y=rel_change)\n",
    "ax.axhline(0, color='black')\n",
    "ax.set_title(\"Percent Change in Number of Procedures\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Population Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = pd.read_csv(\"data/edInc2.csv\")\n",
    "cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = cps.replace({'educ':{1:\"<HS\", 2:\"HS\", 3:\"<BA\", 4:\"BA\", 5:\">BA\"}})\n",
    "cps.columns = ['Education', 'Gender', 'Income']\n",
    "cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick our colors specifically using color_palette()\n",
    "blue_red = [\"#397eb7\", \"#bf1518\"]\n",
    "with sns.color_palette(sns.color_palette(blue_red)):\n",
    "    ax = sns.pointplot(data=cps, x=\"Education\", y=\"Income\", hue=\"Gender\")\n",
    "\n",
    "ax.set_title(\"2014 Median Weekly Earnings\\nFull-Time Workers over 25 years old\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the income gap as a relative quantity between men and women. Recall that the structure of the dataframe is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calls for using `groupby` by Gender, so that we can separate the data for both genders, and then compute the ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = cps.set_index(\"Education\").groupby(\"Gender\")\n",
    "men = cg.get_group(\"Men\").drop(\"Gender\", axis=\"columns\")\n",
    "women = cg.get_group(\"Women\").drop(\"Gender\", axis=\"columns\")\n",
    "display(men, women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfratio = men/women\n",
    "mfratio.columns = [\"Income Ratio (M/F)\"]\n",
    "mfratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=mfratio, markers=True, legend=False);\n",
    "ax.set_ylabel(\"Ratio\")\n",
    "ax.set_title(\"M/F Income Ratio as a function of education level\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the alternate ratio, F/M instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmratio = women/men\n",
    "fmratio.columns = [\"Income Ratio (F/M)\"]\n",
    "fmratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=fmratio, markers=True, legend=False);\n",
    "ax.set_ylabel(\"Ratio\")\n",
    "ax.set_title(\"F/M Income Ratio as a function of education level\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2 Emissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = pd.read_csv(\"data/CAITcountryCO2.csv\", skiprows=2,\n",
    "                  names=[\"Country\", \"Year\", \"CO2\"], encoding=\"ISO-8859-1\")\n",
    "co2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year = co2.Year.iloc[-1]\n",
    "last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"Country != 'World' and Country != 'European Union (15)' and Year == {last_year}\"\n",
    "top14_lasty = co2.query(q).sort_values('CO2', ascending=False).iloc[:14]\n",
    "top14_lasty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top14 = co2[co2.Country.isin(top14_lasty.Country) & (co2.Year >= 1950)]\n",
    "print(len(top14.Country.unique()))\n",
    "top14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "linestyles = ['-', '--', ':', '-.' ]\n",
    "colors = plt.cm.Dark2.colors\n",
    "lines_c = cycler('linestyle', linestyles)\n",
    "color_c = cycler('color', colors)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_prop_cycle(color_c * lines_c)\n",
    "\n",
    "x, y ='Year', 'CO2'\n",
    "for name, df in top14.groupby('Country'):\n",
    "    ax.semilogy(df[x], df[y], label=name)\n",
    "\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel(f\"{y} Emissions (million tons)\")\n",
    "ax.legend(ncol=2, frameon=True, fontsize=11);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
