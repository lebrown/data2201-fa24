{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69c68d6-f286-4279-a70d-f96297ed5622",
   "metadata": {},
   "source": [
    "# Lecture 8 - Data Cleaning \n",
    "\n",
    "### DATA 2201, Fall 2024 \n",
    "\n",
    "*Adapted from Data 100 and DSC 80* \n",
    "\n",
    "Covers the 4 pillars of Data Cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77312ade-f957-40ab-b914-7883fdc2e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from IPython.display import display, IFrame, HTML\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f9730-0e9a-4db5-ad90-5981c96409b3",
   "metadata": {},
   "source": [
    "## Food Safety Demo \n",
    "\n",
    "### Dataset overview \n",
    "\n",
    "From [this article](https://inewsource.org/2023/02/09/san-diego-restaurants-food-safety-violations/) ([archive link](https://archive.ph/gz8BL)):\n",
    "\n",
    "> In the last three years, one third of San Diego County restaurants have had at least one major food safety violation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f7e1b-38cc-4809-b9e2-c84f02b1f890",
   "metadata": {},
   "source": [
    "#### 99% Of San Diego Restaurants Earn â€˜A' Grades, Bringing Usefulness of System Into Question\n",
    "\n",
    "From [this article](https://www.nbcsandiego.com/news/local/99-of-san-diego-restaurants-earn-a-grades-bringing-usefulness-of-system-into-question/25381/) ([archive link](https://archive.ph/yB6RU)):\n",
    "\n",
    "> Food held at unsafe temperatures. Employees not washing their hands. Dirty countertops. Vermin in the kitchen. An expired restaurant permit.\n",
    "> \n",
    "> Restaurant inspectors for San Diego County found these violations during a routine health inspection of a diner in La Mesa in November 2016. Despite the violations, the restaurant was awarded a score of 90 out of 100, the lowest possible score to achieve an â€˜Aâ€™ grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750dee3-50d7-4014-9a3b-262356253be3",
   "metadata": {},
   "source": [
    "### The data \n",
    "\n",
    "- We downloaded the data about the 1000 restaurants closest to UCSD from [here](https://www.sandiegocounty.gov/content/sdc/deh/fhd/ffis/intro.html.html).\n",
    "- We had to download the data as JSON files, then process it into DataFrames. You'll learn how to do this soon!\n",
    "    - Until now, you've (largely) been presented with CSV files that `pd.read_csv` could load without any issues.\n",
    "    - But there are many different formats and possible issues when loading data in from files.\n",
    "    - See [Chapter 8 of Learning DS](https://learningds.org/ch/08/files_intro.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de206fb-3029-4fa5-94cf-d8b0af7048ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll see the Path(...) / subpath syntax a lot.\n",
    "# It creates the correct path to your file, \n",
    "# whether you're using Windows, macOS, or Linux.\n",
    "rest_path = Path('data') / 'restaurants.csv'\n",
    "insp_path = Path('data') / 'inspections.csv'\n",
    "viol_path = Path('data') / 'violations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55508f6-cf15-4960-914b-d60d0b8f4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.read_csv(rest_path)\n",
    "insp = pd.read_csv(insp_path)\n",
    "viol = pd.read_csv(viol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980278d-2fce-4040-9b2c-0f2515411d41",
   "metadata": {},
   "source": [
    "#### Review the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a79f6-4063-447d-9b15-caf39eb0326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa7d5f-f802-4158-b03a-29c2663594b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c44fa-4afd-4d3a-94f6-3a969078cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce04748-b244-4d2f-8558-3fefba5a7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3755b-ecd9-4376-b210-8bc420909a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57db366-33b4-4517-8dbe-3a6c8a6270d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927e0ee-630c-4fd7-aab6-b39529d4217c",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "\n",
    "### Four Pillars of Data Cleaning \n",
    "\n",
    "When loading in a dataset, to clean the data â€“ that is, to prepare it for further analysis â€“ we will:\n",
    "\n",
    "1. Perform **data quality checks**.\n",
    "\n",
    "2. Identify and handle **missing values**.\n",
    "\n",
    "3. Perform **transformations**, including converting time series data to **timestamps**.\n",
    "\n",
    "4. Modify **structure** as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c29e6a-69c2-4898-9896-5e3ef23ed511",
   "metadata": {},
   "source": [
    "## Data Cleaning: Data quality checks \n",
    "\n",
    "We often start an analysis by checking the quality of the data.\n",
    "\n",
    "- Scope: Do the data match your understanding of the population? \n",
    "- Measurements and values: Are the values reasonable?\n",
    "- Relationships: Are related features in agreement?\n",
    "- Analysis: Which features might be useful in a future analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba0c8c-1c05-427f-bb96-f8e1d3595c3d",
   "metadata": {},
   "source": [
    "### Scope\n",
    "\n",
    "Do the data match your understanding of the population?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6d46a-7cba-4524-98b6-7061574b2ef8",
   "metadata": {},
   "source": [
    "We were told that we're only looking at the 1000 restaurants closest to UCSD, so the restaurants in `rest` should agree with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391af82-0aea-41d9-93da-b41c431531f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0863e92-c327-4547-906c-8298f7811f71",
   "metadata": {},
   "source": [
    "### Measurements and values \n",
    "\n",
    "Are the values reasonable? \n",
    "\n",
    "Do the values in the `'grade'` column match what we'd expect grades to look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca8fcf-7b03-43e0-bd14-db58ff03b672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0ccf9c-f045-4d00-b0ee-351736eea986",
   "metadata": {},
   "source": [
    "What kinds of information does the `insp` DataFrame hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e31c98-a58d-4099-8faa-05c123d8d9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c073e71-b1c9-40a5-92b6-3ab86d09c207",
   "metadata": {},
   "source": [
    "What's going on in the `'address'` column of `rest`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31042d7-27e2-4bab-b727-301bcf1aa6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there multiple restaurants with the same address?\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82156f52-4424-4954-9469-ea542ec27e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps all rows with duplicate addresses.\n",
    "(\n",
    "    rest\n",
    "    .groupby('address')\n",
    "    .filter(lambda df: df.shape[0] >= 2)\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216b538-5f9b-42e4-9b84-9543e1fe3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same thing as above!\n",
    "(\n",
    "    rest[rest.duplicated(subset=['address'], keep=False)]\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48204a36-f858-4049-895d-f3ab576f5d8b",
   "metadata": {},
   "source": [
    "### Relationships \n",
    "\n",
    "Are related features in agreement? \n",
    "\n",
    "\n",
    "Do the `'address'`es and `'zip'` codes in `rest` match? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbf7e6-ba8e-436b-ae95-e11b1c9d69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest[['address', 'zip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eba835-bf47-4773-9610-17d9bfc9a29a",
   "metadata": {},
   "source": [
    "What about the `'score'`s and `'grade'`s in `insp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d40627-4d96-444a-9a04-547b6708afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393eec7-a8e9-4aa5-844a-89115a9af639",
   "metadata": {},
   "source": [
    "### Analysis \n",
    "\n",
    "\n",
    "Which features might be useful in a future analysis?\n",
    "\n",
    "- We're most interested in:\n",
    "    - These columns in the `rest` DataFrame: `'business_id'`, `'name'`, `'address'`, `'zip'`, and `'opened_date'`.\n",
    "    - These columns in the `insp` DataFrame: `'business_id'`, `'inspection_id'`, `'score'`, `'grade'`, `'completed_date'`, and `'status'`.\n",
    "    - These columns in the `viol` DataFrame: `'inspection_id'`, `'violation'`, `'major_violation'`, `'violation_text'`, and `'violation_accela'`.\n",
    "\n",
    "- Also, let's rename a few columns to make them easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f4c2c-b95a-4306-bcbd-014c5720eb2e",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Pro-Tip: Using `pipe`\n",
    "\n",
    "When we manipulate DataFrames, it's best to define individual functions for each step, then use the `pipe` **method** to chain them all together.\n",
    "\n",
    "The `pipe` DataFrame method takes in a function, which itself takes in a DataFrame and returns a DataFrame.\n",
    "\n",
    "- In practice, we would add functions one by one to the top of a notebook, then `pipe` them all.\n",
    "- For today, will keep re-running `pipe` to show data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319096a-aa7b-4d33-8300-d85e3aeb4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_rest(rest):\n",
    "    return rest[['business_id', 'name', 'address', 'zip', 'opened_date']]\n",
    "\n",
    "rest = (\n",
    "    pd.read_csv(rest_path)\n",
    "    .pipe(subset_rest)\n",
    ")\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ac8a1-5105-4967-93b6-86bf6e9667ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above â€“ but the above makes it easier to chain more .pipe calls afterwards.\n",
    "subset_rest(pd.read_csv(rest_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d6dea-240a-4050-83a2-09173207631a",
   "metadata": {},
   "source": [
    "Let's use `pipe` to keep (and rename) the subset of the columns we care about in the other two DataFrames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb61f0-18d1-491c-8762-dd0246e9de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_insp(insp):\n",
    "    return (\n",
    "        insp[['business_id', 'inspection_id', 'score', 'grade', 'completed_date', 'status']]\n",
    "        .rename(columns={'completed_date': 'date'})\n",
    "    )\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae3b6f-993f-4675-9fca-ebe99d9a7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_viol(viol):\n",
    "    return (\n",
    "        viol[['inspection_id', 'violation', 'major_violation', 'violation_accela']]\n",
    "        .rename(columns={'violation': 'kind',\n",
    "                         'major_violation': 'is_major',\n",
    "                         'violation_accela': 'violation'})\n",
    "    )\n",
    "\n",
    "viol = (\n",
    "    pd.read_csv(viol_path)\n",
    "    .pipe(subset_viol)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd81d4-5460-47a4-9224-30a0b8140d47",
   "metadata": {},
   "source": [
    "### Combining the restaurant data\n",
    "\n",
    "Let's join all three DataFrames together so that we have all the data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911892c-3bb7-4ef4-a6b3-c53c9805eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_restaurant_data():\n",
    "    return (\n",
    "        rest\n",
    "        .merge(insp, on='business_id', how='left')\n",
    "        .merge(viol, on='inspection_id', how='left')\n",
    "    )\n",
    "\n",
    "df = merge_all_restaurant_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565d2bc-955b-4d5d-a2e6-2977222e467f",
   "metadata": {},
   "source": [
    "## Data Cleaning: Missing Values \n",
    "\n",
    "Next, it's important to check for and handle missing values, as they can have a big effect on your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eed8f1-1997-4f63-9a1f-274aa748f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a11eb-bf4a-4e90-bc5f-faf5db387801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proportion of values in each column that are missing.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fadf25-978b-4ea6-8104-82bffbac8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are there null values here?\n",
    "# insp['inspection_id'] and viol['inspection_id'] don't have any null values...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b59485-ece1-4daf-8a28-e1f13564ec28",
   "metadata": {},
   "source": [
    "There are many ways of handling missing values, which we'll cover more shortly. But a good first step is to check how many there are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a600ef3-3cf6-48af-b62a-9512505ccaba",
   "metadata": {},
   "source": [
    "## Data Cleaning: Transformations and timestamps \n",
    "\n",
    "Transformations: \n",
    "\n",
    "> A transformation results from performing some operation on every element in a sequence, e.g. a Series.\n",
    "\n",
    "It's often useful to look at ways of transforming your data to make it easier to work with.\n",
    "\n",
    "- Type conversions (e.g. changing the string `\"$2.99\"` to the number `2.99`).\n",
    "\n",
    "- Unit conversion (e.g. feet to meters).\n",
    "\n",
    "- Extraction (Getting `'vermin'` out of `'Vermin Violation Recorded on 10/10/2023'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3ae644-c085-4a5b-81cd-89f302350db9",
   "metadata": {},
   "source": [
    "### Creating timestamps\n",
    "\n",
    "Most commonly, we'll parse dates into `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3818f-e77f-484b-876f-5fed64c8607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype!\n",
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ac55a-d2b4-4df2-86b3-4a23b540183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This magical string tells Python what format the date is in.\n",
    "# For more info: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "date_format = '%Y-%m-%d'\n",
    "pd.to_datetime(insp['date'], format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ad708-0d7b-4e94-b237-20812c4f913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another advantage of defining functions is that we can reuse this function\n",
    "# for the 'opened_date' column in `rest` if we wanted to.\n",
    "def parse_dates(insp, col):\n",
    "    date_format = '%Y-%m-%d'\n",
    "    dates = pd.to_datetime(insp[col], format=date_format)\n",
    "    return insp.assign(**{col: dates})\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    "    .pipe(parse_dates, 'date')\n",
    ")\n",
    "\n",
    "# We should also remake df, since it depends on insp.\n",
    "# Note that the new insp is used to create df!\n",
    "df = merge_all_restaurant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd489db-1180-4897-8d18-f2cb5bee0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype now!\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87cc86-2618-4449-8b44-63b10cb444f6",
   "metadata": {},
   "source": [
    "### Working with timestamps \n",
    "\n",
    "- We often want to adjust granularity of timestamps to see overall trends, or seasonality.\n",
    "- Use the `resample` method in `pandas` ([documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)).\n",
    "    - Think of it like a version of `groupby`, but for timestamps.\n",
    "    - For instance, `insp.resample('2W', on='date')` separates every two weeks of data into a different group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10547e-a24d-419f-8e86-873480dda7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.resample('2W', on='date').mean(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4419ba-8d41-41fb-8085-e4df7007eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are those numbers coming from?\n",
    "insp[\n",
    "    (insp['date'] >= pd.Timestamp('2020-01-05')) &\n",
    "    (insp['date'] < pd.Timestamp('2020-01-19'))\n",
    "]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b604276-5a9a-469f-9cbc-85cda3b3e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "(insp.resample('2W', on='date')\n",
    " .size()\n",
    " .plot(title='Number of Inspections Over Time')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289e3cf-29b3-40bf-9ebf-eb39b2a89a3c",
   "metadata": {},
   "source": [
    "### The `.dt` accessor \n",
    "\n",
    "You have already seen how to use the `.dt` accessor for properties of timestamps ([documentation](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5717763-555d-4856-ad9b-4d2b2c6f470c",
   "metadata": {},
   "source": [
    "## Data Cleaning: Modifying structure \n",
    "\n",
    "### Reshaping DataFrames\n",
    "\n",
    "We often **reshape** the DataFrame's structure to make it more convenient for analysis. For example, we can:\n",
    "\n",
    "- Simplify structure by removing columns or taking a set of rows for a particular period of time or geographic area.\n",
    "    - We already did this!\n",
    "\n",
    "- Adjust granularity by aggregating rows together.\n",
    "    - To do this, use `groupby` (or `resample`, if working with timestamps).\n",
    "\n",
    "- Reshape structure, most commonly by using the DataFrame `melt` method to un-pivot a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c972ced-bded-4152-adec-c48a65f16240",
   "metadata": {},
   "source": [
    "### Using `melt`\n",
    "\n",
    "- The `melt` method is common enough that we'll give it a special mention.\n",
    "- We'll often encounter pivot tables (esp. from government data), which we call *wide* data.\n",
    "- The methods we've introduced work better with *long-form* data, or *tidy* data.\n",
    "- To go from wide to long, `melt`.\n",
    "\n",
    "<center><img src='imgs/wide-vs-long.svg' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbca45-f360-42a0-863b-0664b0cd7d22",
   "metadata": {},
   "source": [
    "### Example usage of `melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0d22f-0fae-473c-a9b0-076d73b6a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example = pd.DataFrame({\n",
    "    'Year': [2001, 2002],\n",
    "    'Jan': [10, 130],\n",
    "    'Feb': [20, 200],\n",
    "    'Mar': [30, 340]\n",
    "}).set_index('Year')\n",
    "wide_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1df05-59cd-4401-9241-bb2d7e06f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example.melt(ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b0a9a-2608-4513-8c3b-89f0b45303ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
