{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 11 ‚Äì Imputation\n",
    "\n",
    "### DATA 2201, Fall 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372709ae-ea4b-4bb5-b80e-a5b39d343ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from IPython.display import display, IFrame, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff6d7f-b4e8-4e32-b491-418318218c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import several helper functions for this lecture, \n",
    "#  Used for plotting and permutation tests\n",
    "from lec11_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Review: Missingness mechanisms.\n",
    "- Identifying missingness mechanisms in data.\n",
    "    - How do we decide between MCAR and MAR using a permutation test?\n",
    "    - The Kolmogorov-Smirnov test statistic.\n",
    "- Imputation.\n",
    "    - Mean imputation.\n",
    "    - Probabilistic imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6a60f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Missingness mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d636748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flowchart\n",
    "\n",
    "A good strategy is to assess missingness in the following order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca60316",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing by design (MD)</b></center>\n",
    "<center><i>Can I determine the missing value exactly by looking at the other columns?</i> ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1b2bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Not missing at random (NMAR)</b></center>\n",
    "<center><i>Is there a good reason why the missingness depends on the values themselves?</i> ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1007fb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing at random (MAR)</b></center>\n",
    "<center><i>Do other columns tell me anything about the likelihood that a value is missing? </i>ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abae3ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing completely at random (MCAR)</b></center>\n",
    "<center><i>The missingness must not depend on other columns or the values themselves. </i>üòÑ</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b48ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick Check\n",
    "\n",
    "<small>_Taken from the Winter 2023 DSC 80 Midterm Exam._</small>\n",
    "    \n",
    "The DataFrame `tv_excl` contains all of the information we have for TV shows that are only available for streaming on a single streaming service.\n",
    "    \n",
    "<center>\n",
    "    <img src=\"imgs/tv-excl.png\" width=60%>\n",
    "</center>\n",
    "    \n",
    "    \n",
    "Given no other information other than a TV show‚Äôs `\"Title\"` and `\"IMDb\"` rating, what is the most likely missingness mechanism of the `\"IMDb\"` column?\n",
    "\n",
    "- A. Missing by design\n",
    "\n",
    "- B. Not missing at random\n",
    "\n",
    "- C. Missing at random\n",
    "\n",
    "- D. Missing completely at random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036ebab-5e7e-472a-b8c4-42cc345da6b4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<details><summary>Solution</summary>\n",
    "    The answer we were looking for is not missing at random (NMAR). As we saw repeatedly in lecture 10, in cases where all we have access to is a single column with missing values, potentially with other unrelated columns (like `\"Title\"` here), the best explanation is that there is some inherent reason as to why the values in the column with missing values are missing. Here, a reasonable interpretation is that the `\"IMDb\"` scores that are missing are likely to come from worse TV shows, and so lower scores are more likely to be missing. Think about it like this ‚Äì if a TV show is really great, presumably more people would know about it, and it would be rated. If a TV show wasn‚Äôt as good and wasn‚Äôt as popular, it is more likely to be ignored.\n",
    "\n",
    "However, partial credit was awarded to those who answered missing completely at random.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d98698",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick Check\n",
    "\n",
    "<small>_Taken from the Winter 2023 DSC 80 Midterm Exam._</small>\n",
    "        \n",
    "<center>\n",
    "    <img src=\"imgs/tv-excl.png\" width=60%>\n",
    "</center>\n",
    "    \n",
    "    \n",
    "Now, suppose we discover that the median `\"Rotten Tomatoes\"` rating among TV shows with a missing `\"IMDb\"` rating is a 13, while the median `\"Rotten Tomatoes\"` rating among TV shows with a present `\"IMDb\"` rating is a 52.\n",
    "\n",
    "Given this information, what is the most likely missingness mechanism of the `\"IMDb\"` column?\n",
    "\n",
    "- A. Missing by design\n",
    "\n",
    "- B. Not missing at random\n",
    "\n",
    "- C. Missing at random\n",
    "\n",
    "- D. Missing completely at random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661debf4-89c8-467f-b2dd-418fb6a4474d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<details><summary>Solution</summary>\n",
    "    The problem tells us that the distribution of `\"Rotten Tomatoes\"` when `\"IMDb\"` is missing (mean 13) is very different from the distribution of `\"Rotten Tomatoes\"` when `\"IMDb\"` is not missing (mean 52). As such, the missingness of `\"IMDb\"` appears to depend on `\"Rotten Tomatoes\"`, and so the most likely missingness mechanism is missing at random.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50521ade",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Review: Example - Heights data \n",
    "\n",
    "Last lecture, we saw an example using height's data for child, mother and father. \n",
    "\n",
    "We saw that if we simulated MAR data, that there appeared to be a difference in the distribution between the non and non-null `'child'` distribution and `'father'` distribution. \n",
    "\n",
    "However, the difference in means for the distributions was very small. \n",
    "\n",
    "Therefore, if we ran a permutation test with the difference in means as our test statistic, we would fail to reject the null.\n",
    "    - **Using just the difference in means, it is hard to tell these two distributions apart.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c06cd1-2fbd-439d-a0f2-a75ebee47d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_path = Path('data') / 'midparent.csv'\n",
    "heights = pd.read_csv(heights_path).rename(columns={'childHeight': 'child'})[['father', 'mother', 'gender', 'child']]\n",
    "\n",
    "def make_missing(r):\n",
    "    rand = np.random.uniform() # Random real number between 0 and 1.\n",
    "    if r['father'] > 72 and rand < 0.5:\n",
    "        return np.NaN\n",
    "    elif r['gender'] == 'female' and rand < 0.3:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return r['child']\n",
    "    \n",
    "heights_mar = heights.copy()\n",
    "heights_mar['child'] = heights_mar.apply(make_missing, axis=1)\n",
    "heights_mar['child_missing'] = heights_mar['child'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e21dcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Kolmogorov-Smirnov test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b01d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Permutation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b376ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Permutation tests help decide whether **two samples look like they were drawn from the same population distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479eea1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In a permutation test, we simulate data under the null by **shuffling** either group labels or numerical features.\n",
    "    - In effect, this **randomly assigns individuals to groups**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1923ff05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the two distributions are **numerical**, we've used as our test statistic the **difference in group means or medians**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524a62e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the two distributions are **categorical**, we've used as our test statistic the **total variation distance (TVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee559907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means\n",
    "\n",
    "The difference in means works well in some cases. Let's look at one such case.\n",
    "\n",
    "Below, we artificially generate two numerical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e01b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "distr1 = pd.Series(np.random.normal(0, 1, size=N // 2))\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(3, 1, size=N // 2))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n",
    "\n",
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad61ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different distributions with the same mean\n",
    "\n",
    "Let's generate two distributions that look very different but have the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a76426",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "a = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "b = pd.Series(np.random.normal(4, 1, size=N//2))\n",
    "distr1 = pd.concat([a,b], ignore_index=True)\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(distr1.mean(), distr1.std(), size=N))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n",
    "\n",
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ce709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, if we use the difference in means as our test statistic in a permutation test, we will fail to reject the null that the two distributions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f99b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "diff_means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the values, while keeping the group labels in place.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the absolute difference in means.\n",
    "    diff_mean = shuffled.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "    diff_means.append(diff_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07361789",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "observed_diff = data.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "fig = px.histogram(pd.DataFrame(diff_means), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the Absolute Difference in Means')\n",
    "fig.add_vline(x=observed_diff, line_color='red', line_width=1, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed Absolute Difference in Means = {round(observed_diff, 2)}</span>',\n",
    "                   x=2 * observed_diff, showarrow=False, y=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The computed p-value is fairly large.\n",
    "np.mean(np.array(diff_means) >= observed_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd283870",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Telling numerical distributions apart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906b144",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The difference in means only works as a test statistic in permutation tests **if the two distributions have similar shapes**.\n",
    "    - It tests to see if one is a shifted version of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8717e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a better test statistic to differentiate between numerical distributions with different shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950de654",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In other words, we need a **distance** metric between numerical.\n",
    "    - The TVD is a distance metric between categorical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c37a95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Kolmogorov-Smirnov test statistic\n",
    "\n",
    "- The K-S test statistic measures the similarity between two distributions.\n",
    "- It is defined in terms of the **cumulative distribution function (CDF)** of a given distribution.\n",
    "    - If $f(x)$ is a distribution, then the CDF $F(x)$ is the proportion of values in distribution $f$ that are less than or equal to $x$.\n",
    "- The K-S statistic is roughly defined as the **largest difference between two CDFs**.\n",
    "<center><img src=./imgs/KS2_Example.png width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587e2a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Aside: Cumulative distribution functions\n",
    "\n",
    "First, some setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05596be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = create_kde_plotly(data, 'group', 'A', 'B', 'data', f'Distributions of A and B')\n",
    "\n",
    "# Think about what this function is doing!\n",
    "def create_cdf(group):\n",
    "    return data.loc[data['group'] == group, 'data'].value_counts(normalize=True).sort_index().cumsum()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(\n",
    "    go.Scatter(x=create_cdf('A').index, y=create_cdf('A'), name='CDF of A')\n",
    ")\n",
    "\n",
    "fig2.add_trace(\n",
    "    go.Scatter(x=create_cdf('B').index, y=create_cdf('B'), name='CDF of B')\n",
    ")\n",
    "\n",
    "fig2.update_layout(title='CDFs of A and B')\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "for i in range(2):\n",
    "    fig2.data[i]['marker']['color'] = fig1.data[i]['marker']['color']\n",
    "    fig2.data[i]['showlegend'] = False\n",
    "    \n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['Distributions', 'CDFs'])\n",
    "fig.add_trace(fig1.data[0], row=1, col=1)\n",
    "fig.add_trace(fig1.data[1], row=1, col=1)\n",
    "fig.add_trace(fig2.data[0], row=1, col=2)\n",
    "fig.add_trace(fig2.data[1], row=1, col=2)\n",
    "fig.update_layout(width=1000, height=400);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3b392",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the CDFs of our two synthetic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb274b1",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc18b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The K-S statistic in Python\n",
    "\n",
    "Fortunately, **we don't need to calculate the K-S statistic ourselves**! Python can do it for us (and you can use this pre-built version in all assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf21cb7-0ed7-4b31-831a-7f6a160a79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head(3))\n",
    "display(data.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb045882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_2samp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86095baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ks = ks_2samp(data.loc[data['group'] == 'A', 'data'], \n",
    "                       data.loc[data['group'] == 'B', 'data']).statistic\n",
    "observed_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d59ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We don't know if this number is big or small. We need to run a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "ks_stats = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the data.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the K-S statistic.\n",
    "    groups = shuffled.groupby('group')['data']\n",
    "    ks_stat = ks_2samp(groups.get_group('A'), \n",
    "                       groups.get_group('B')).statistic\n",
    "    ks_stats.append(ks_stat)\n",
    "    \n",
    "ks_stats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fd255",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(ks_stats), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the K-S Statistic')\n",
    "fig.add_vline(x=observed_ks, line_color='red', line_width=1, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed KS = {round(observed_ks, 2)}</span>',\n",
    "                   x=0.8 * observed_ks, showarrow=False, y=0.16)\n",
    "\n",
    "fig.update_layout(xaxis_range=[0, 0.2])\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(ks_stats) >= observed_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15934f5",
   "metadata": {},
   "source": [
    "We were able to differentiate between the two distributions using the K-S test statistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49301fbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `ks_2samp`\n",
    "\n",
    "* `scipy.stats.ks_2samp` actually returns **both** the statistic **and** a p-value.\n",
    "* The p-value is calculated using the permutation test we just performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7360aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(data.loc[data['group'] == 'A', 'data'], data.loc[data['group'] == 'B', 'data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db1889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means vs. K-S statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c14df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The K-S statistic measures the difference between two numerical distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f42a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It **does not** quantify if one is larger than the other on average, so there are times we still need to use the difference in means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d1259",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Strategy: Always plot the two distributions you are comparing.\n",
    "    - If the distributions have similar shapes but are centered in different places, use the difference in means (or absolute difference in means).\n",
    "    - If your alternative hypothesis involves a \"direction\" (i.e. smoking weights were are on average than non-smoking weights), use the difference in means.\n",
    "    - If the distributions have different shapes but roughly the same center, and your alternative hypothesis is simply that the two distributions are different, use the K-S statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057756ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Heights -  Missingness of `'child'` heights on `'father'`'s heights (MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27634d9c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "heights_mar['child_missing'] = heights_mar['child'].isna()\n",
    "create_kde_plotly(heights_mar[['child_missing', 'father']], \n",
    "                  'child_missing', True, False, 'father',\n",
    "                  \"Father's Height by Missingness of Child Height (MAR example)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc833c45",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above picture shows us that missing `'child'` heights tend to come from taller `'father'`s heights.\n",
    "\n",
    "- To determine whether the two distributions are significantly different, we must use a permutation test. This time, the difference in means is not a good choice, since the centers are similar but the shapes are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a205f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performing the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc17c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(heights_mar.query('child_missing')['father'], heights_mar.query('not child_missing')['father'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d55de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The p-value is very small, so we conclude that the child height is MAR, conditional on the father's height.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74869575",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44562e8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we do with missing data?\n",
    "\n",
    "- Suppose we are interested in a dataset $Y$. \n",
    "- We get to **observe** $Y_{obs}$, while the rest of the dataset, $Y_{mis}$, is **missing**.\n",
    "- Issue: $Y_{obs}$ may look quite different than $Y$.\n",
    "    - The mean and other measures of central tendency may be different.\n",
    "    - The variance may be different.\n",
    "    - The correlations between variables may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859698f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 1: Dropping missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762c1d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the data are MCAR (missing completely at random), then dropping the missing values entirely doesn't significantly change the data.\n",
    "    - For instance, the mean of the dataset post-dropping is an unbiased estimate of the true mean.\n",
    "    - This is because MCAR data is a **random sample** of the full dataset.\n",
    "    - From DSC 10, we know that random samples tend to resemble the larger populations they are drawn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e1f1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **If the data are not MCAR, then dropping the missing values will introduce bias.**\n",
    "    - MCAR is rare!\n",
    "    - For instance, suppose we asked people \"How much do you give to charity?\" People who give little are less likely to respond, so the average response is **biased high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f898576",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Listwise deletion\n",
    "\n",
    "- _Listwise deletion_ is the act of dropping entire rows that contain missing values.\n",
    "- Issue: This can delete perfectly good data in other columns for a given row.\n",
    "    - Improvement: Drop missing data only when working with the column that contains missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6716964",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To illustrate, let's generate two datasets with missing `'child'` heights ‚Äì one in which the heights are MCAR, and one in which they are MAR dependent on `'gender'` only.\n",
    "\n",
    "**In practice, you'll have to run permutation tests to determine the likely missingness mechanism first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926585b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "heights_mcar = make_mcar(heights, 'child', pct=0.5)\n",
    "heights_mar = make_mar_on_cat(heights, 'child', 'gender', pct=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd708948",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Below, we compute the means and standard deviations of the `'child'` column in all three datasets. Remember, `.mean()` and `.std()` ignore missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb177bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_describe({\n",
    "    'Original': heights,\n",
    "    'MCAR': heights_mcar,\n",
    "    'MAR': heights_mar\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c74b86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observations:\n",
    "\n",
    "- The `'child'` mean (and SD) in the MCAR dataset is very close to the true `'child'` mean (and SD).\n",
    "\n",
    "- The `'child'` mean in the MAR dataset is biased **high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf5f05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 2: Imputation\n",
    "\n",
    "**Imputation** is the act of filling in missing data with plausable values. Ideally, imputation:\n",
    "\n",
    "* is quick and easy to do.\n",
    "* shouldn't introduce bias into the dataset.\n",
    "\n",
    "These are hard to do at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf869e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Kinds of imputation\n",
    "\n",
    "- There are three main types of imputation, two of which we will focus on today:\n",
    "\n",
    "    - **Imputation with a single value: mean, median, mode.**\n",
    "    - Imputation with a single value, using a model: regression, kNN.\n",
    "    - **Probabilistic imputation by drawing from a distribution.**\n",
    "\n",
    "- Each has upsides and downsides, and **each works differently with different types of missingness**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3bca0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa679e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- Mean imputation is the act of filling in missing values in a column with the mean of the observed values in that column.\n",
    "- This strategy:\n",
    "    - üëç Preserves the mean of the observed data, for all types of missingness.\n",
    "    - üëé Decreases the variance of the data, for all types of missingness.\n",
    "    - üëé Creates a biased estimate of the true mean when the data are not MCAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158145a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Mean imputation in the MCAR `heights` dataset\n",
    "\n",
    "Let's look at two distributions:\n",
    "- The distribution of the `'child'` column in `heights`, where we have all the data.\n",
    "- The distribution of the `'child'` column in `heights_mcar`, where some values are MCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look in util.py to see how multiple_kdes is defined.\n",
    "multiple_kdes({'Original': heights, 'MCAR, Unfilled': heights_mcar})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ed603",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since the `'child'` heights are MCAR, the <span style='color:rgb(217,95,2)'><b> orange distribution, in which some values are missing</b></span>, has roughly the same shape as the <span style='color:rgb(27,158,119)'><b>turquoise distribution, which has no missing values</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c0acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MCAR data\n",
    "\n",
    "Let's fill in missing values in `heights_mcar['child']` with the mean of the observed `'child'` heights in `heights_mcar['child']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar_mfilled = heights_mcar.fillna(heights_mcar['child'].mean())\n",
    "heights_mcar_mfilled['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {'Original': heights, 'MCAR, Unfilled': heights_mcar, 'MCAR, Mean Imputed': heights_mcar_mfilled}\n",
    "multiple_describe(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7284d51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observations:\n",
    "\n",
    "- The mean of the imputed dataset is the same as the mean of the subset of heights that aren't missing (which is close to the true mean).\n",
    "\n",
    "- The standard deviation of the imputed dataset smaller than that of the other two datasets. **Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7958e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Let's visualize all three distributions: the original, the MCAR heights with missing values, and the mean-imputed MCAR heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568711a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580208d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Takeaway**: When data are MCAR and you impute with the mean:\n",
    "- The mean of the imputed dataset is an **unbiased estimator** of the true mean.\n",
    "- The variance of the imputed dataset is smaller than the variance of the full dataset.\n",
    "    - Mean imputation tricks you into thinking your data are more reliable than they are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb4ea3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Mean imputation in the MAR `heights` dataset\n",
    "\n",
    "- When data are MAR, mean imputation leads to biased estimates of the mean across groups.\n",
    "\n",
    "- The bias may be different in different groups.\n",
    "    - For example: If the missingness depends on gender, then different genders will have differently-biased means.\n",
    "    - The overall mean will be biased towards one group.\n",
    "\n",
    "- Again, let's look at two distributions:\n",
    "    - The distribution of the `'child'` column in `heights`, where we have all the data.\n",
    "    - The distribution of the `'child'` column in `heights_mar`, where some values are MAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a8917",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "multiple_kdes({'Original': heights, 'MAR, Unfilled': heights_mar})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f57b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distributions are not very similar!\n",
    "\n",
    "Remember that in reality, you won't get to see the <span style='color:rgb(27,158,119)'><b>turquoise distribution, which has no missing values</b></span> ‚Äì instead, you'll try to recreate it, using your sample with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fe43b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MAR data\n",
    "\n",
    "Let's fill in missing values in `heights_mar['child']` with the mean of the observed `'child'` heights in `heights_mar['child']` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11675c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar_mfilled = heights_mar.fillna(heights_mar['child'].mean())\n",
    "heights_mar_mfilled['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {'Original': heights, 'MAR, Unfilled': heights_mar, 'MAR, Mean Imputed': heights_mar_mfilled}\n",
    "multiple_describe(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab62dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the latter two means are biased **high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a92a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Let's visualize all three distributions: the original, the MAR heights with missing values, and the mean-imputed MAR heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41cddd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the sample with MAR values was already biased high, mean imputation kept the sample biased ‚Äì it did not bring the data **closer to the data generating process**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab1f17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With our single mean imputation strategy, the resulting female mean height is biased quite high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7147d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    heights.groupby('gender')['child'].mean().rename('Original'),\n",
    "    heights_mar.groupby('gender')['child'].mean().rename('MAR, Unfilled'),\n",
    "    heights_mar_mfilled.groupby('gender')['child'].mean().rename('MAR, Mean Imputed')\n",
    "], axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca40b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Within-group (conditional) mean imputation\n",
    "\n",
    "* **Improvement**: Since MAR data are MCAR within each group, we can perform group-wise mean imputation.\n",
    "    - In our case, since the missingness of `'child'` is dependent on `'gender'`, we can impute separately for each `'gender'`.\n",
    "    - For instance, if there is a missing `'child'` height for a `'female'` child, impute their height with the mean observed `'female'` height.\n",
    "\n",
    "- With this technique, the overall mean remains unbiased, as do the within-group means.\n",
    "\n",
    "- Like with \"single\" mean imputation, the variance of the dataset is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02c4a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `transform` returns!\n",
    "\n",
    "- In MAR data, imputation by the overall mean gives a biased estimate of the mean of each group. \n",
    "- To obtain an unbiased estimate of the mean within each group, impute using the mean within each group.\n",
    "- To perform an operation separately to each gender, we `groupby('gender')` and use the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_impute(s):\n",
    "    return s.fillna(s.mean())\n",
    "\n",
    "heights_mar_cond = heights_mar.groupby('gender')['child'].transform(mean_impute).to_frame()\n",
    "heights_mar_cond['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map['MAR, Conditional Mean Imputed'] = heights_mar_cond\n",
    "multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dbbba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The <span style='color:rgb(231,41,138)'><b>pink distribution</b></span> does a slightly better job of approximating the <span style='color:rgb(27,158,119)'><b>turquoise distribution</b></span> than the <span style='color:rgb(117,112,179)'><b>purple distribution</b></span>, but not by much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a894f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: Imputation with single values\n",
    "\n",
    "- Imputing missing data in a column with the mean of the column:\n",
    "    - faithfully reproduces the mean of the observed dataset,\n",
    "    - reduces the variance, and\n",
    "    - biases relationships between the column and other columns if the data are not MCAR.\n",
    "    \n",
    "- The same is true with other statistics (e.g. median and mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dff83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f5afd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imputing missing values using distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663e546",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, each missing value in a column has been filled in with a constant value.\n",
    "    - This creates \"spikes\" in the imputed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec5f08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea**: We can **probabilistically** impute missing data from a distribution.\n",
    "    - We can fill in missing data by drawing from the distribution of the **non-missing** data.\n",
    "    - There are 5 missing values? Pick 5 values from the data that aren't missing.\n",
    "     - How? Using `np.random.choice` or `.sample`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3922ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the data are MCAR, then sample from the entire column of present values. If the data are MAR on some categorical column, then sample from the present values separately for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032be30d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Probabilistic imputation in the MAR `heights` dataset\n",
    "\n",
    "Let's use `transform` to call `prob_impute` separately on each `'gender'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e698c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_impute(s):\n",
    "    s = s.copy()\n",
    "    \n",
    "    # Step 1: Find the number of missing child heights for that gender.\n",
    "    num_null = s.isna().sum()\n",
    "    \n",
    "    # Step 2: Sample num_null observed child heights for that gender.\n",
    "    fill_values = np.random.choice(s.dropna(), num_null)\n",
    "    \n",
    "    # Step 3: Fill in missing values and return ser.\n",
    "    s[s.isna()] = fill_values\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e28916",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar_pfilled = heights_mar.copy()\n",
    "heights_mar_pfilled['child'] = (\n",
    "    heights_mar\n",
    "    .groupby('gender')\n",
    "    ['child']\n",
    "    .transform(prob_impute)\n",
    ")\n",
    "heights_mar_pfilled['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9919f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_map['MAR, Conditionally Probabilistically Imputed'] = heights_mar_pfilled\n",
    "multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4daed6a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The <b><span style=\"color:#67a61f\">green distribution (conditional probabilistic imputation)</span></b> does the best job of approximating the <b><span style=\"color:#1c9e76\">turqoise distribution (the full dataset with no missing values)</span></b>!\n",
    "\n",
    "_Remember that the graph above is interactive ‚Äì you can hide/show lines by clicking them in the legend._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf71df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "- With this technique, the missing values were filled in with observed values in the dataset.\n",
    "\n",
    "- If a value was never observed in the dataset, it will never be used to fill in a missing value.\n",
    "    - For instance, if the observed heights were 68, 69, and 69.5 inches, we will never fill a missing value with 68.5 inches even though it's a perfectly reasonable height.\n",
    "\n",
    "- Solution? Create a histogram (with `np.histogram`) to bin the data, then sample from the histogram.\n",
    "    - See Lab 5, Question 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86e579",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Randomness\n",
    "\n",
    "- Unlike mean imputation, probabilistic imputation is **random** ‚Äì each time you run the cell in which imputation is performed, the results could be different.\n",
    "\n",
    "- If we're interested in estimating some population **parameter** given our (incomplete) sample, it's best not to rely on just a single random imputation.\n",
    "\n",
    "- **Multiple imputation**: Generate multiple imputed datasets and aggregate the results!\n",
    "    - Similar to bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8ef63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of imputation techniques\n",
    "\n",
    "* Listwise deletion.\n",
    "* Mean imputation.\n",
    "* Group-wise (conditional) mean imputation.\n",
    "* Probabilistic imputation.\n",
    "* Multiple imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a2875",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Listwise deletion\n",
    "\n",
    "* Procedure: `df = df.dropna()`.\n",
    "* If data are MCAR, listwise deletion doesn't change most summary statistics (mean, median, SD) of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f440f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Mean imputation \n",
    "\n",
    "* Procedure: `df[col] = df[col].fillna(df[col].mean())`.\n",
    "* If data are MCAR, the resulting mean is an unbiased estimate of the true mean, but the variance is too low.\n",
    "* Analogue for categorical data: imputation with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5b192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Conditional mean imputation\n",
    "\n",
    "* Procedure: for a column `c1`, conditional on a second categorical column\n",
    "`c2`:\n",
    "\n",
    "```py\n",
    "means = df.groupby('c2').mean().to_dict()\n",
    "imputed = df['c1'].apply(lambda x: means[x] if np.isnan(x) else x)\n",
    "```\n",
    "\n",
    "* If data are MAR, the resulting mean is an unbiased estimate of the true mean, but the variance is too low.\n",
    "* This increases correlations between the columns.\n",
    "* If the column with missing values were dependent on *more than one* column, we can use linear regression to predict the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ffe56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Probabilistic imputation\n",
    "\n",
    "* Procedure: draw from the distribution of **observed data** to fill in missing values.\n",
    "* If data are MCAR, the resulting mean and variance are unbiased estimates of the true mean and variance.\n",
    "* Extending to the MAR case: draw from **conditional empirical distributions**.\n",
    "    - If data are conditional on a single categorical column `c2`, apply the MCAR procedure to the groups of `df.groupby(c2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef74415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Multiple imputation\n",
    "\n",
    "* Procedure:\n",
    "    - Apply probabilistic imputation multiple times, resulting in $m$ imputed datasets.\n",
    "    - Compute statistics separately on the $m$ imputed datasets (e.g. compute the mean or correlation coefficient).\n",
    "    - Plot the distribution of these statistics and create confidence intervals.\n",
    "* If a column is missing conditional on multiple columns, your \"multiple imputations\" should include probabilistic imputations for each!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
