{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 ‚Äì Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must submit this assignment to Gradescope by the on-time deadline. **We strongly encourage you to plan to submit your work to Gradescope several days (hours) before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "Please read the instructions carefully when you are submitting your work to Gradescope.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random number generator seed\n",
    "np.random.seed(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" markdown=\"1\">\n",
    "\n",
    "You cannot use `for`-loops in Homework\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "##  Hypothesis Testing\n",
    "\n",
    "In this section, you'll practice using terms and structure of hypothesis testing.\n",
    "\n",
    "The first step is always to define what you're looking at, create your hypotheses, and set a level of significance (i.e. a p-value cutoff). Once you've done that, you can find a p-value.\n",
    "\n",
    "If all of these words are foreign, look at the Lecture 9 notebook and the readings, and don't forget to think about the real-world meaning of these terms!  The following example describes a real-world scenario, which should help keep it easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì Baking Sale üßÅ\n",
    "\n",
    "At MTU, students are looking to buy treats at a bake sale in the Library. There is a pop-up bake stand selling cookies and cupcakes to students. Last Saturday, this stand sold 250 cookies to MTU students. After eating the cookies, 15 students complained that their cookies were burnt, leaving a bitter taste in their mouths. In response to the student dissatisfaction, the stand claims that 96% of their cookies are baked perfectly without any burning. You think this seems unlikely and decide to investigate.\n",
    "\n",
    "First, select a significance level for your investigation. You don't need to turn this in anywhere. Then, answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 1a \n",
    "\n",
    "\n",
    "Returns your answer(s) to the following question **as a list** in variable `q1a_result`.\n",
    "\n",
    "What are reasonable choices for the **null hypothesis** for your investigation? Select all that apply.\n",
    "1. The stand sells cookies that are approximately 4% burnt. \n",
    "2. The stand sells cookies that are 96% perfectly baked.\n",
    "3. The stand sells cookies that are less than 96% perfectly baked. \n",
    "4. The stand sells cookies that are at least 4% burnt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1a_result = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "#### Question 1b\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `cookies_p_value`\n",
    "\n",
    "Complete the implementation of the function `cookies_p_value`, which takes in an integer `N` and returns the estimated p-value of your investigation upon simulating the null hypothesis `N` times. (The p-value is an estimate of the true theoretical p-value of your test since it relies on simulation.)\n",
    "\n",
    "***Note***: When thinking about the null distribution for this problem.  It is most similar to the \"Coin Flipping\" example in the review of hypothesis testing notebook.  Except in this case, you do not expect the probability to be a fair coin, 0.5, but rather the probability of burnt / not-burnt under the null hypothesis.  \n",
    "\n",
    "***Note***: Plot the null distribution and your observed statistic to check your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cookies_p_value(N): \n",
    "    # Input: int N \n",
    "    # Returns estimated p-value upon simulating the null hypothesis N times\n",
    "    \n",
    "    ...\n",
    "    return None \n",
    "cookies_p_value(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten our feet wet with hypothesis testing, let's take a closer look at how to choose null and alternative hypotheses and test statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì Tires üöó\n",
    "\n",
    "A tire manufacturer, TritonTire, claims that their tires are so good, they will bring a Toyota Highlander from 60 MPH to a complete stop in under 106 feet, 95% percent of the time.\n",
    "\n",
    "Now, you own a Toyota Highlander equipped with TritonTire tires, and you decide to test this claim. You take your car to an empty Vons parking lot, speed up to exactly 60 MPH, hit the brakes, and measure the stopping distance. As illegal as it is, you repeat this process 50 times and find that **you stopped in under 106 feet only 47 of the 50 times**.\n",
    "\n",
    "Livid, you call TritonTire and say that their claim is false. They say, no, that you were just unlucky: your experiment is consistent with their claim. But they didn't realize that they are dealing with a *data scientist*.\n",
    "\n",
    "To settle the matter, you decide to unleash the power of the hypothesis test. The following three subparts ask you to answer a total of four select-all multiple choice questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 2a: `car_null_hypothesis` and `car_alt_hypothesis`\n",
    "\n",
    "You will set up a hypothesis test in order to test your suspicion that the tires are are actually worse than claimed. Which of the following are valid null and alternative hypotheses for this hypothesis test?\n",
    "\n",
    "1. The tires will stop your car in under 106 feet exactly 95% of the time.\n",
    "2. The tires will stop your car in under 106 feet less than 95% of the time.\n",
    "3. The tires will stop your car in under 106 feet greater than 95% of the time.\n",
    "4. The tires will stop your car in more than 106 feet exactly 5% of the time.\n",
    "5. The tires will stop your car in more than 106 feet less than 5% of the time.\n",
    "6. The tires will stop your car in more than 106 feet greater than 5% of the time.\n",
    "\n",
    "Set the variable, `car_null_hypothesis`, to a list of integers, corresponding to the the valid null hypotheses above.\n",
    "\n",
    "Set the variable, `car_alt_hypothesis`, to a list of integers, corresponding to the valid alternative hypotheses above given your observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car_null_hypothesis = ...\n",
    "car_alt_hypothesis = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 4.2: `car_test_stat`\n",
    "\n",
    "Which of the following are valid test statistics for our question?\n",
    "\n",
    "1. The number of times the car stopped in under 106 feet in 50 attempts.\n",
    "2. The average number of feet the car took to come to a complete stop in 50 attempts.\n",
    "3. The number of attempts it took before the car stopped in under 95 feet.\n",
    "4. The proportion of attempts in which the car stopped in under 106 feet in 50 attempts.\n",
    "\n",
    "Set the variable, `car_test_stat`, to a list of integers, corresponding to the valid test statistics above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car_test_stat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 4.3: `car_p_value`\n",
    "\n",
    "The p-value is the probability, under the assumption the null hypothesis is true, of observing a test statistic **equal to our observed statistic, or more extreme in the direction of the alternative hypothesis**.\n",
    "\n",
    "Why don't we just look at the probability of observing a test statistic equal to our observed statistic? That is, why is the \"more extreme in the direction of the alternative hypothesis\" part necessary?\n",
    "\n",
    "1. Because our observed test statistic isn't extreme.\n",
    "2. Because our null hypothesis isn't suggesting equality.\n",
    "3. Because the probability of finding our observed test statistic equals the probability of finding something more extreme.\n",
    "4. Because if we run more and more trials, the probability of observing any particular test statistic gets closer and closer to zero.\n",
    "\n",
    "Set the variable `car_p_value`, to the correct reason as an **integer** (not a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car_p_value = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### Question 3 ‚Äì Superheroes ü¶∏\n",
    "\n",
    "In the previous two questions, we ran hypothesis tests that didn't require us to look at stored data. In this next question, we'll return to the `heroes` DataFrame from Lab 5, which is read in from the file `data/superheroes.csv`.\n",
    "\n",
    "Our goal in this section will be to answer the question:\n",
    "\n",
    "> Are there significantly **more** \"good\" blond-haired, blue-eyed characters than the general pool of characters?\n",
    "\n",
    "To answer this question, we will conduct a hypothesis test. You choose the following null hypothesis:\n",
    "\n",
    "> The proportion of \"good\" characters among blond-haired, blue-eyed characters is equal to the proportion of \"good\" characters in the sample population from the current `heroes` DataFrame.\n",
    "\n",
    "and alternative hypothesis: \n",
    "\n",
    "> the distribution of \"good\" characters among blond-haired, blue-eyed characters is greater than the proportion of \"good\" characters in the overall population.\n",
    "\n",
    "To proceed with the hypothesis test, we will need to determine the test statistics for our test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 3a `superheroes_test_stat`\n",
    "\n",
    "Which of the following are valid test statistics for our question?\n",
    "\n",
    "1. The difference in proportions for \"good\" characters among blond-haired, blue-eyed characters and \"good\" characters in the overall population. \n",
    "2. The number of \"good\" characters that are blond-haired, blue-eyed.\n",
    "3. The proportion of blond-haired, blue-eyed characters among all \"good\" characters.\n",
    "4. The absolute difference in proportions for \"good\" characters among blond-haired, blue-eyed characters and \"good\" characters in the overall population.\n",
    "\n",
    "Assign the variable `superheroes_test_stat`, to a list of integers, corresponding to all the valid test statistics above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "superheroes_test_stat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "#### Question 3b`bhbe_col`\n",
    "\n",
    "Regardless of your choice for the above question, we will use the test statistic stated below to complete the implementations of the following functions:\n",
    "\n",
    "> The proportion of \"good\" characters among blond-haired, blue-eyed characters.\n",
    "\n",
    "To start, complete the implementation of the function `bhbe_col`, which takes in a DataFrame like `heroes` and returns a Boolean Series that contains `True` for characters that have **both** blond hair and blue eyes, and `False` for all other characters. \n",
    "\n",
    "***Note***: If a character's hair color contains the word `'blond'`, uppercase or lowercase, we consider their hair to be blond for the purposes of this question. Similarly, if a character's eye color contains the word `'blue'`, uppercase or lowercase, we consider their eye color to be blue for the purposes of this question.\n",
    "\n",
    "Fix a significance level (i.e. p-value cutoff) of 1%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bhbe_col(df): \n",
    "    # Input a DataFrame like \"heroes\"\n",
    "    # Returns a Boolean Series\n",
    "    #  True for characters that have both blond hair and blue eyes \n",
    "    #  False for all other characters\n",
    "\n",
    "    return None\n",
    "\n",
    "superheroes_fp = Path('data') / 'superheroes.csv'\n",
    "heroes = pd.read_csv(superheroes_fp, index_col=0)\n",
    "bhbe_out = bhbe_col(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 3c `superheroes_observed_stat`\n",
    "\n",
    "Complete the implementation of the function `superheroes_observed_stat`, which takes in a DataFrame like `heroes` and returns the observed test statistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def superheroes_observed_stat(df): \n",
    "    # Input a DataFrame like \"heroes\"\n",
    "    # Returns the observed test statistic\n",
    "\n",
    "    return None\n",
    "\n",
    "obs_stat_out = superheroes_observed_stat(heroes)\n",
    "obs_stat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 3d `simulate_bhbe_null` \n",
    "Complete the implementation of the function `simulate_bhbe_null`, which takes in a DataFrame like `heroes` and a positive integer `N` and returns an array of length `N`, where each element is a simulated test statistic according to the null hypothesis.\n",
    "\n",
    "***Hint***: Like in `superheroes_observed_stat`, you'll need to use both `bhbe_col` and information in the `heroes` DataFrame to complete your simulation. Remember that you cannot use `for`-loops in this question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_bhbe_null(df, N): \n",
    "    # Input a DataFrame like \"heroes\" and an integer N\n",
    "    # Returns array of length N with each element a simulated test statistic\n",
    "\n",
    "    return None\n",
    "\n",
    "simulate_bhbe_out = simulate_bhbe_null(heroes, 10)\n",
    "simulate_bhbe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 3e `superheroes_p_value` \n",
    "Complete the implementation of the function `superheroes_p_value`, which takes in DataFrame like `heroes` and returns a list where:\n",
    "* The first element is the p-value for the hypothesis test, using 10,000 simulations.\n",
    "* The second element is `'Reject'` if you reject the null hypothesis and `'Fail to reject'` if you fail to reject the null hypothesis, at the 1% significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def superheroes_p_value(df): \n",
    "    # Input a DataFrame like \"heroes\" \n",
    "    # Returns list where the first element is the p-value using 100000 sims \n",
    "    #  the 2nd element is a string to 'Reject' or 'Fail to reject' the null hyp\n",
    "\n",
    "    return None \n",
    "    \n",
    "\n",
    "pval_out = superheroes_p_value(heroes)\n",
    "pval_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done HW 5!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers.  If you run into any issues when running this cell, feel free to check the [Debugging Guide](https://mtu.instructure.com/courses/1527249/pages/debugging-guide).\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw05",
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1a_result, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(q1a_result).issubset({1, 2, 3, 4})\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": [
      6
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ans = cookies_p_value(1000)\n>>> 0 < ans < 0.6\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(car_null_hypothesis) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(car_alt_hypothesis) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(car_test_stat) <= set(range(1, 5))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> car_p_value in set(range(1, 5)) \nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(car_p_value, int)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(superheroes_test_stat) <= set(range(1, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(superheroes_test_stat, list)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(bhbe_out, pd.Series)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bhbe_out.dtype == np.dtype('bool')\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0.5 <= obs_stat_out <= 1.0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": [
      1,
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(simulate_bhbe_out, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> simulate_bhbe_out.shape[0] == 10\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> ((0.45 <= simulate_bhbe_out) & (simulate_bhbe_out <= 1)).all()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3e": {
     "name": "q3e",
     "points": [
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(pval_out, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(pval_out[1], str)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(pval_out) == 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= pval_out[0] <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> pval_out[1] in ['Reject', 'Fail to reject']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
