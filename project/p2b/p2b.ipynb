{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"p2b.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project 2b: Predicting Housing Prices in Cook County\n",
    "\n",
    "\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for submission support.\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope. \n",
    "\n",
    "If you run into issues with pandas, jupyter notebook, etc. look at the [Debugging Guide](https://mtu.instructure.com/courses/1527249/pages/debugging-guide).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds_utils import *\n",
    "from feature_func_hw12 import *\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training, validation, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists('cook_county_train_val.csv')):\n",
    "    with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "        item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is split into a training set, a validation set, and a test set. Importantly, the test set does not contain values for our target variable, `Sale Price`. In this project, you will train a model on the training and validation sets and then use this model to predict the `Sale Price`s of the test set. In the cell below, we load the training and validation sets into the `DataFrame` `training_val_data` and the test set into the `DataFrame` `test_data`.\n",
    "\n",
    "Note, we are using a sample of the full data set in order to speed-up analysis and use less memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data = pd.read_csv(\"cook_county_train_val.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"cook_county_contest_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the shape of the data matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 81916 observations and 62 features in training data\n",
    "assert training_val_data.shape == (81916, 62)\n",
    "# 20480 observations and 61 features in test data\n",
    "assert test_data.shape == (20480, 61)\n",
    "# Sale Price is provided in the training/validation data\n",
    "assert 'Sale Price' in training_val_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's remind ourselves of the data available to us in the Cook County dataset. Remember, a more detailed description of each variable is included in `codebook.txt`, which is in the same directory as this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CCAO Dataset\n",
    "\n",
    "You'll work with the dataset from the Cook County Assessor's Office (CCAO) in Illinois. This government institution determines property taxes across most of Chicago's metropolitan areas and nearby suburbs. In the United States, all property owners must pay property taxes, which are then used to fund public services, including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models considering multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "However, this system is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing \"[racially discriminatory assessments and taxes](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html).\" The lawsuit included claims that the assessor's office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines. Wealthy homeowners, who were typically white, [paid less in property taxes](https://fix8media-chicago.squarespace.com/bpnc-v-berrios-resource-page), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, \"[The Tax Divide](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html),\" delves into how this was uncovered. After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments had been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "Make sure to watch [the video](https://youtu.be/PvxMAukFvJE?feature=shared&t=80) before answering the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 5\n",
    "\n",
    "It is time to build your own model!\n",
    "\n",
    "You will conduct feature engineering on your training data using the `feature_engine_final` function (you will define this in `q5d`), fit the model with this training data, and compute the training Root Mean Squared Error (RMSE). Then, we will process our test data with `feature_engine_final`, use the model to predict `Log Sale Price` for the test data, transform the predicted and original log values back into their original forms (by using `delog`), and compute the test RMSE.\n",
    "\n",
    "Your goal in Question 5 is to:\n",
    "\n",
    "* Define a function to perform feature engineering and produce a design matrix for modeling.\n",
    "* Apply this feature engineering function to the training data and use it to train a model that can predict the `Log Sale Price` of houses.\n",
    "* Use this trained model to predict the `Log Sale Price`s of the test set. Remember that our test set does not contain the true `Sale Price` of each house –— your model is trying to guess them! \n",
    "* Submit your predicted `Log Sale Price`s on the test set to Gradescope.\n",
    "\n",
    "\n",
    "Right under the grading scheme, we will outline some important Datahub logistics. **Please make sure you read this carefully to avoid running into memory issues later!**\n",
    "\n",
    "* In Question 5a, you can explore possible features for your model. This portion is **not graded**.\n",
    "* In Question 5b, you can perform EDA on the dataset. This portion is **not graded**.\n",
    "* In Question 5c, you can define feature engineering helper functions. This portion is **not graded**.\n",
    "* In Question 5d, you will create your design matrix and train a model. This portion is **is graded**.\n",
    "* In Question 5e, you can fit and evaluate your model. This portion is **not graded**.\n",
    "* In Question 5f, you will generate the predictions for the test set. This portion is **is graded**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Scheme\n",
    "\n",
    "Your grade for Question 5 will be based on your model's RMSE when making predictions on the training set, as well as your model’s RMSE when making predictions on the test set. The tables below provide scoring guidelines. If your RMSE lies in a particular range, you will receive the number of points associated with that range.\n",
    "\n",
    "**Important**: while your training RMSE can be checked at any time in this notebook, your test RMSE can only be checked by submitting your model’s predictions to Gradescope. **You will only be able to submit your test set predictions to Gradescope up to 5 times per day**. Attempts will not carry over across days, so we recommend planning ahead to make sure you have enough time to finetune your model! \n",
    "\n",
    "The thresholds are as follows:\n",
    "\n",
    "Points | 9 | 6 | 3 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Training RMSE | Less than 200k | [200k, 240k) | [240k, 280k) | More than 280k\n",
    "\n",
    "Points | 9 | 6 | 3 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 240k | [240k, 280k) | [280k, 300k) | More than 300k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Some notes before you start\n",
    "\n",
    "- **If you are running into memory issues, restart the kernel and only run the cells you need to.** The cell below (question cell) contains most to all of the imports necessary to successfully complete this portion of the project, so it can be completed independently code-wise from the remainder of the project, and you do not need to rerun the cell at the top of this notebook. The autograder will have more than 4GB of memory, so you will not lose credit as long as your solution to Question 5 is within the total memory (4GB) limits of Datahub. If you want to delete specific variables, you may also use `del`. For example, the following code will free up memory from data used for older models: `del training_val_data, test_data`. Our staff solution can be run independently from all other questions, so we encourage you to do the same to make debugging easier.\n",
    "- **If you need the data again after deleting the variables or resetting, you must reload them again from earlier in the notebook.**\n",
    "- You will be predicting `Log Sale Price` on the data stored in `cook_county_contest_test.csv`. We will delog/exponentiate your prediction on Gradescope to compute RMSE and use this to score your model. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e., if one of your `Log Sale Price` predictions is 60, it is too large; $e^{60}$ is too big!)\n",
    "- You MUST remove any additional new cells you add before submitting to Gradescope to avoid any autograder errors. \n",
    "- **You can only submit your test set prediction CSV file to Gradescope up to 5 times per day. Start early!** \n",
    "\n",
    "**PLEASE READ THE ABOVE MESSAGE CAREFULLY!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5a: Finding Potential Features\n",
    "\n",
    "**This question is not graded** – it is intended to give helpful guidance on how to get started with feature engineering in `q5d`. You may write as little or as much as you would like here; it will not factor into your grade. Read the documentation about the dataset in `codebook.txt`, located in this directory. Is there any data you think may be related to housing prices? Include them below for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5b: More EDA\n",
    "\n",
    "\n",
    "**This question is not graded** – it is intended to give helpful guidance on how to get started with feature engineering. You may write as little or as much as you would like here; it will not factor into your grade. Use the scratch space below to conduct any additional EDA you would like to see. You may use this space to make additional plots to help you visualize the relationship between any variables or compute any relevant statistics. You are free to add any number of cells as needed below and before the next question. You may find it helpful to review Project A1 and the techniques we explore there.\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>[<b>Click to Expand</b>] Some potential ideas. </summary>\n",
    "    \n",
    "* Plot the distribution of a variable. Is this variable heavily skewed? Are there any outliers? This can inform how you engineer your features later on.\n",
    "\n",
    "* Make a scatter plot between a continuous feature and the outcome. Is there a relationship? Is there a transformation that may linearize the relationship?\n",
    "\n",
    "* Make a plot of a categorical/discrete feature and the outcome. Is there a relationship? How can we transform this categorical data into numerical features that can be useful for OLS?\n",
    "\n",
    "* Find the correlation coefficient between features and the outcome. Is there a strong relationship between the two? Can you find the correlation coefficient between different transformations of the feature and the outcome?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add any EDA code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5c: Defining Helper Function or Helper Variables\n",
    "\n",
    "**This question is not graded, but we suggest that you put all your helper functions below for readability and ease of testing.** Use this space below to define any additional helper functions you may use in your final model. These can be transformation functions you identified in the optional question above. \n",
    "\n",
    "**Note 1:** We have automatically imported staff implementations of the functions you wrote in HW 12. These functions are `remove_outliers`, `add_total_bedrooms`, `find_expensive_neighborhoods`, `add_in_expensive_neighborhood`, and `ohe_roof_material`. You are welcome to add additional helper functions that may add in creating your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define any additional helper functions or variables you need here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5d: Defining The Pipeline Function\n",
    "\n",
    "You should encapsulate as much of your workflow into functions as possible. Your job is to select better features and define your own feature engineering pipeline inside the function `feature_engine_final` in the following cell. Use of `.pipe` is not required, but you are welcome to incorporate it! **You must not change the parameters inside `feature_engine_final`. Do not edit the three lines at the end of the question cell below. They are helper functions that define a linear model, fit your data, and compute RMSE. If you do, you will receive no credit for this question.** \n",
    "\n",
    "- Any feature engineering techniques that involve referencing `Sale Price` (for example, removing outlying `Sale Price` values from the training data) should be performed under the condition `if not is_test_set:`.\n",
    "- All other feature engineering techniques should be applied to both the training and test sets. This means that you should perform them under the condition `else:`.\n",
    "- When `is_test_set` is `True`, your function should return only the design matrix, `X`.\n",
    "- When `is_test_set` is `False`, your function should return both the design matrix and the response variable `Y` (the `Log Sale Price` column).\n",
    "\n",
    "**Hints:**\n",
    "-  Some features may have missing values in the test set but not in the training/validation set. Make sure `feature_engine_final` handles missing values appropriately for each feature.\n",
    "- We have imported all feature engineering functions from HW 12 for you. You do not have access to the `feature_func.py` file with the function body and definitions, but they work as defined in HW 12. Feel free to use them as you see fit!\n",
    "- You may wish to consider removing outlying datapoints from the training set before fitting your model. You may not, however, remove any datapoints from the test set (after all, the CCAO could not simply \"refuse\" to make predictions for a particular house!)\n",
    "- As you finetune your model, you may unintentionally consume too much Datahub memory, causing your kernel to crash. See `q5a` for guidance on how to resolve this!!\n",
    "\n",
    "Look back to Project 2a Question 3a and the `feature_engine_simple` function to understand a similar (but simpler) approach.\n",
    "\n",
    "**Note:** If you run into any errors, the [Proj. 2 Common Mistakes](https://mtu.instructure.com/courses/1527249/pages/debugging-guide-p2-common-questions) may be a helpful resource.\n",
    "\n",
    "**Summary** \n",
    "Think about what features (and do some EDA on them) you want to include in your model.  Use existing feature transformation function (those from HW12 are available to you, e.g., `remove_outliers`, `add_total_bedrooms`, `find_expensive_neighborhoods`, `add_in_expensive_neighborhood`, and `ohe_roof_material`) or write your own helper functions.  The function you complete belows carries out the feature transformation and selection of variables to include in your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please include all of your feature engineering processes inside this function.\n",
    "# Do not modify the parameters of this function.\n",
    "def feature_engine_final(data, is_test_set=False):\n",
    "    # Whenever you access 'Log Sale Price' or 'Sale Price', make sure to use the\n",
    "    # condition is_test_set like this:\n",
    "\n",
    "\n",
    "    if not is_test_set:\n",
    "        # Processing for the training set (i.e. not the test set)\n",
    "        # CAN involve references to sale price!\n",
    "        # CAN involve filtering certain rows or removing outliers\n",
    "        data['Log Sale Price'] = np.log(data['Sale Price'])\n",
    "        ...\n",
    "    else:\n",
    "        # Processing for the test set\n",
    "        # CANNOT involve references to sale price!\n",
    "        # CANNOT involve removing any rows\n",
    "        ...\n",
    "        \n",
    "    # Processing for both test and training set\n",
    "    # CANNOT involve references to sale price!\n",
    "    # CANNOT involve removing any rows\n",
    "    ...\n",
    "    \n",
    "    \n",
    "    # Return predictors (X) and response (Y) variables separately\n",
    "    if is_test_set:\n",
    "        # Predictors \n",
    "        X = ...\n",
    "        return X\n",
    "    else:\n",
    "        # Predictors. Your X should not include Log Sale Price!\n",
    "        X = ...\n",
    "        # Response variable\n",
    "        Y = ...\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "# DO NOT EDIT THESE THREE LINES!\n",
    "check_rmse_threshold = run_linear_regression_test_optim(lm.LinearRegression(fit_intercept=True), \n",
    "                                                        feature_engine_final, \n",
    "                                                        'cook_county_train_val.csv', \n",
    "                                                        None, False)\n",
    "print(\"Current training RMSE:\", check_rmse_threshold.loss)\n",
    "print(\"You can check your grade for your prediction as per the grading scheme outlined at the start of Question 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5e: Fit and Evaluate your Model\n",
    "\n",
    "**This question is not graded.** Use this space below to evaluate your models. Some ideas are listed below. \n",
    "\n",
    "**Note:** While we have a grader function that checks RMSE for you, it is best to define and create your own model object and fit on your data. This way, you have access to the model directly to help you evaluate/debug if needed. For this project, you should use a `sklearn` default `LinearRegression()` model with intercept term for grading purposes. Do not modify any hyperparameter in `LinearRegression()`, and focus on feature selection or hyperparameters of your own feature engineering function.\n",
    "\n",
    "It may also be helpful to calculate the RMSE directly as follows:\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in the set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of houses}}}$$\n",
    "\n",
    "A function that computes the RMSE is provided below. Feel free to use it if you would like calculate the RMSE for your training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values.\n",
    "    Input:\n",
    "      predicted (1D array): Vector of predicted/fitted values\n",
    "      actual (1D array): Vector of actual values\n",
    "    Output:\n",
    "      A float, the RMSE value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>[<b>Click to Expand</b>] Hints: </summary>\n",
    "    \n",
    "Train set:\n",
    "\n",
    "* Check your RMSE. Is this a reasonable number? You may use our grading scheme as a reference. Keep in mind that training error is generally less than testing error. \n",
    "\n",
    "Test set:\n",
    "* Find the original data shape at the beginning of the notebook (in the provided assert statement). What should the output shape be?\n",
    "\n",
    "* Since test and training/validation sets come from the same population (recall that test and training/validation sets are a random split from larger data), we expect our test prediction to have a similar range as the validation data. Plot the observed training (Log) Sale Price and the predicted (Log) Sale Price. Are the ranges similar? Do you have any unreasonable extreme prediction that cannot be exponentiated?\n",
    "\n",
    "* We cannot compute test RMSE directly since we do not have the observed values. Perform cross-validation to estimate your test error. Recall that we are treating the validation set as unseen data.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this space to evaluate your model\n",
    "# if you reset your memory, you need to define the functions again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5f Submission\n",
    "\n",
    "Recall that the test set given to you in this assignment does not contain values for the true `Sale Price` of each house. You will be predicting `Log Sale Price` on the data stored in `cook_county_contest_test.csv`. To determine your model's RMSE on the test set, you will submit the predictions made by your model to Gradescope. There, we will run checks to see what your test RMSE is by considering (hidden) true values for the `Sale Price`. We will delog/exponentiate your prediction on Gradescope to compute RMSE and use this to score your model. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e., if one of your `Log Sale Price` predictions is 60, it is too large; $e^{60}$ is too big!)\n",
    "\n",
    "Your score on this section will be determined by the grading scheme outlined at the start of Question 5. **Remember that you can only submit your test set predictions to Gradescope up to 5 times per day. Plan your time to ensure that you can adjust your model as necessary, and please test your model's performance using cross-validation before making any submissions.** For more on cross-validation, check Lecture 25/26. In particular, the [Lecture 26 notebook](https://mtu.2i2c.cloud/hub/user-redirect/git-pull?repo=https%3A%2F%2Fwww.github.com%2Flebrown%2Fdata2201-fa24&urlpath=lab%2Ftree%2Fdata2201-fa24%2Flectures%2Flec26%2Flec26.ipynb&branch=main) may be helpful here. You can also feel free to reference what you did in previous questions and P2a when creating training and validation sets and seeing how your model performs.\n",
    "\n",
    "\n",
    "**Note:** If you run into any errors, the [Proj. 2 Common Mistakes](https://mtu.instructure.com/courses/1527249/pages/debugging-guide-p2-common-questions) may be a helpful resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL, it is making your predictions on the test set \n",
    "Y_test_pred = run_linear_regression_test(lm.LinearRegression(fit_intercept=True), \n",
    "                                         feature_engine_final, None, 'cook_county_train_val.csv', \n",
    "                                         'cook_county_contest_test.csv', \n",
    "                                         is_test = True, is_ranking = False, return_predictions = True\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch space to check if your prediction is reasonable. See 5e for hints. \n",
    "# We will not reset the submission count for mis-submission issues.\n",
    "pd.DataFrame(Y_test_pred).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing your prediction model for home sale prices in Cook County! In the following section, we'll delve deeper into the implications of predictive modeling within the CCAO case study, especially because statistical modeling is how the CCAO valuates properties. \n",
    "\n",
    "Refer to the [video](https://youtu.be/PvxMAukFvJE?feature=shared&t=80) if you're having trouble getting started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 6: Exploring RMSE\n",
    "\n",
    "Let's delve a bit deeper into what RMSE means in the context of predicting house prices. We will go through different ways of visualizing the performance of the model you created and see how that ties into questions about property taxes. To this end, we'll create the `preds_df` `DataFrame` below that will prove useful for the later questions.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell below; no further action is needed\n",
    "train_df = pd.read_csv('cook_county_train_val.csv')\n",
    "X, Y_true = feature_engine_final(train_df)\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X, Y_true)\n",
    "Y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame({'True Log Sale Price' : Y_true, 'Predicted Log Sale Price' : Y_pred, \n",
    "                         'True Sale Price' : np.e**Y_true, 'Predicted Sale Price' : np.e**Y_pred})\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 6a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how our model performs on two halves of our data: `cheap_df` which contains the rows of `preds_df` with prices below or equal to the median sale price, and `expensive_df` which has rows of `preds_df` with true sale prices above the median. Take a moment to understand what is happening in the cell below, as it will also prove useful in `q6b`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell below to obtain the two subsets of data; no further action is needed.\n",
    "min_Y_true, max_Y_true = np.round(np.min(Y_true), 1) , np.round(np.max(Y_true), 1)\n",
    "median_Y_true = np.round(np.median(Y_true), 1)\n",
    "cheap_df = preds_df[(preds_df['True Log Sale Price'] >= min_Y_true) & (preds_df['True Log Sale Price'] <= median_Y_true)]\n",
    "expensive_df = preds_df[(preds_df['True Log Sale Price'] > median_Y_true) & (preds_df['True Log Sale Price'] <= max_Y_true)]\n",
    "\n",
    "print(f'\\nThe lower interval contains houses with true sale price ${np.round(np.e**min_Y_true)} to ${np.round(np.e**median_Y_true)}')\n",
    "print(f'The higher interval contains houses with true sale price ${np.round(np.e**median_Y_true)} to ${np.round(np.e**max_Y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the RMSE of your model's predictions of `Sale Price` on each subset separately**, and assign those values to `rmse_cheap` and `rmse_expensive` respectively.\n",
    "\n",
    "Separately, we also want to understand whether the proportion of houses in each interval that the model overestimates the value of the actual `Sale Price`. To that end, **compute the proportion of predictions strictly greater than the corresponding true price in each subset**, and assign it to `prop_overest_cheap` and `prop_overest_expensive` respectively. For example, if we were working with a dataset of 3 houses where the actual `Log Sale Price`s were [10, 11, 12] and the model predictions were [5, 15, 13], then the proportion of houses with overestimated values would be 2/3.\n",
    "\n",
    "**Note:** When calculating `prop_overest_cheap` and `prop_overest_expensive`, you could use either `Log Sale Price` or `Sale Price`. Take a second to think through why this metric is unchanged under a log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_cheap = ...\n",
    "rmse_expensive = ...\n",
    "\n",
    "prop_overest_cheap = ...\n",
    "prop_overest_expensive = ...\n",
    "\n",
    "print(f\"The RMSE for properties with log sale prices in the interval {(min_Y_true, median_Y_true)} is {np.round(rmse_cheap)}\")\n",
    "print(f\"The RMSE for properties with log sale prices in the interval {(median_Y_true, max_Y_true)} is {np.round(rmse_expensive)}\\n\")\n",
    "print(f\"The percentage of overestimated values for properties with log sale prices in the interval {(min_Y_true, median_Y_true)} is {np.round(100 * prop_overest_cheap, 2)}%\")\n",
    "print(f\"The percentage of overestimated values for properties with log sale prices in the interval {(median_Y_true, max_Y_true)} is {np.round(100 * prop_overest_expensive, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 6b\n",
    "\n",
    "The intervals we defined above were rather broad. Let's try and take a more fine-grained approach to understand how RMSE and proportion of houses overestimated vary across different intervals of `Log Sale Price`. Complete the functions `rmse_interval` and `prop_overest_interval` to allow us to compute the appropriate values for any given interval. Pay close attention to the function description, and feel free to reuse and modify the code you wrote in the previous part as needed.\n",
    "\n",
    "**Note:** The autograder tests provided for each of the functions are **not** comprehensive as the outputs of the function are highly dependent on your model. Make sure that the values you obtain are interpretable and that the plots that follow look right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse_interval(df, start, end):\n",
    "    '''\n",
    "    Given a design matrix X and response vector Y, computes the RMSE for a subset of values \n",
    "    wherein the corresponding Log Sale Price lies in the interval [start, end].\n",
    "\n",
    "    Input: \n",
    "    df : pandas DataFrame with columns 'True Log Sale Price', \n",
    "        'Predicted Log Sale Price', 'True Sale Price', 'Predicted Sale Price'\n",
    "    start : A float specifying the start of the interval (inclusive)\n",
    "    end : A float specifying the end of the interval (inclusive)\n",
    "    '''\n",
    "    subset_df = ...\n",
    "\n",
    "    rmse_subset = ...\n",
    "    return rmse_subset\n",
    "    \n",
    "def prop_overest_interval(df, start, end):\n",
    "    '''\n",
    "    Given a DataFrame df, computes prop_overest for a subset of values \n",
    "    wherein the corresponding Log Sale Price lies in the interval [start, end].\n",
    "\n",
    "    Input: \n",
    "    df : pandas DataFrame with columns 'True Log Sale Price', \n",
    "        'Predicted Log Sale Price', 'True Sale Price', 'Predicted Sale Price'\n",
    "    start : A float specifying the start of the interval (inclusive)\n",
    "    end : A float specifying the end of the interval (inclusive)\n",
    "    '''\n",
    "    \n",
    "    subset_df = ...\n",
    "\n",
    "    # DO NOT MODIFY THESE TWO LINES\n",
    "    if subset_df.shape[0] == 0:\n",
    "        return -1\n",
    "\n",
    "    prop_subset = ...\n",
    "    return prop_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "### Question 6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've defined these functions, let's put them to use and generate some interesting visualizations of how the RMSE and proportion of overestimated houses vary for different intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE plot\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.subplot(1, 2, 1) \n",
    "rmses = []\n",
    "for i in np.arange(8, 14, 0.5):\n",
    "    rmses.append(rmse_interval(preds_df, i, i + 0.5))\n",
    "plt.bar(x = np.arange(8.25, 14.25, 0.5), height = rmses, edgecolor = 'black', width = 0.5)\n",
    "plt.title('RMSE Over Different Intervals\\n of Log Sale Price', fontsize = 10)\n",
    "plt.xlabel('Log Sale Price')\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "# Overestimation plot  \n",
    "plt.subplot(1, 2, 2)\n",
    "props = []\n",
    "for i in np.arange(8, 14, 0.5):\n",
    "    props.append(prop_overest_interval(preds_df, i, i + 0.5) * 100) \n",
    "plt.bar(x = np.arange(8.25, 14.25, 0.5), height = props, edgecolor = 'black', width = 0.5)\n",
    "plt.title('Percentage of House Values Overestimated \\nover different intervals of Log Sale Price', fontsize = 10)\n",
    "plt.xlabel('Log Sale Price')\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.ylabel('Percentage of House Values\\n that were Overestimated (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly referencing **ONE** of the plots above (using `props` and `rmses`), explain whether the assessments your model predicts more closely aligns with scenario C or scenario D that we discussed back in `q1b` on P2a. Which of the two plots would be more useful in ascertaining whether the assessments tended to result in progressive or regressive taxation? Provide a brief explanation to support your choice of plot. For your reference, the scenarios are also shown below:\n",
    "\n",
    "    C. An assessment process that systematically overvalues inexpensive properties and undervalues expensive properties.  \n",
    "    D. An assessment process that systematically undervalues inexpensive properties and overvalues expensive properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 7: Evaluating the Model in Context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Question 7a\n",
    "\n",
    "When evaluating your model, we used RMSE. In the context of estimating the value of houses, what does the residual mean for an individual homeowner? How does it affect them in terms of property taxes? Discuss the cases where the residual is positive and negative separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In the case of the Cook County Assessor’s Office, Chief Data Officer Rob Ross states that fair property tax rates are contingent on whether property values are assessed accurately —— that they’re valued at what they’re worth, relative to properties with similar characteristics. This implies that having a more accurate model results in fairer assessments. The goal of the property assessment process for the CCAO, then, is to be as accurate as possible. \n",
    "\n",
    "When the use of algorithms and statistical modeling has real-world consequences, we often refer to the idea of fairness as a measurement of how socially responsible our work is. Fairness is incredibly multifaceted: Is a fair model one that minimizes loss - one that generates accurate results? Is it one that utilizes \"unbiased\" data? Or is fairness a broader goal that takes historical contexts into account?\n",
    "\n",
    "These approaches to fairness are not mutually exclusive. If we look beyond error functions and technical measures of accuracy, we'd not only consider _individual_ cases of fairness but also what fairness —— and justice —— means to marginalized communities on a broader scale. We'd ask: What does it mean when homes in predominantly Black and Hispanic communities in Cook County are consistently overvalued, resulting in proportionally higher property taxes? When the white neighborhoods in Cook County are consistently undervalued, resulting in proportionally lower property taxes? \n",
    "\n",
    "Having \"accurate\" predictions doesn't necessarily address larger historical trends and inequities, and fairness in property assessments in taxes works beyond the CCAO's valuation model. Disassociating accurate predictions from a fair system is vital to approaching justice at multiple levels. Take Evanston, IL —— a suburb in Cook County —— as an example of housing equity beyond just improving a property valuation model: their City Council members [recently approved reparations for African American residents](https://www.usnews.com/news/health-news/articles/2021-03-23/chicago-suburb-approves-government-reparations-for-black-residents).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 7b\n",
    "\n",
    "Reflecting back on your exploration in Questions 6 and 7a, in your own words, what makes a model's predictions of property values for tax assessment purposes \"fair\"? \n",
    "\n",
    "This question is open-ended and part of your answer may depend on your specific model; we are looking for thoughtfulness and engagement with the material, not correctness. \n",
    "\n",
    "**Hint:** Some guiding questions to reflect on as you answer the question above: What is the relationship between RMSE, accuracy, and fairness as you have defined it? Is a model with a low RMSE necessarily accurate? Is a model with a low RMSE necessarily \"fair\"? Is there any difference between your answers to the previous two questions? And if so, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Congratulations on finishing P2b!\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "\n",
    "\n",
    "**Please make sure you submit the following to the right assignments:**\n",
    "\n",
    "* **Project 2b:** Submit the zip file generated by using the `grader.export()` cell provided below.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that everything was generated and submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p2b",
   "require_no_pdf_confirmation": true,
   "tests": {
    "q5d": {
     "name": "q5d",
     "points": [
      3,
      3,
      3,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> check_rmse_threshold(200000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> check_rmse_threshold(240000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> check_rmse_threshold(280000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> check_rmse_threshold.signature == (feature_engine_final, 'cook_county_train_val.csv', None)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5f": {
     "name": "q5f",
     "points": [
      1,
      3,
      3,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Y_test_pred.shape[0] == test_data.shape[0]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> if (os.path.exists('cook_county_test.csv')):\n...     test = pd.read_csv('cook_county_test.csv')\n...     cond = rmse(np.exp(Y_test_pred), test['Sale Price']) < 240000\n... else: \n...     cond = False\n>>> cond == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> if (os.path.exists('cook_county_test.csv')):\n...     test = pd.read_csv('cook_county_test.csv')\n...     cond = rmse(np.exp(Y_test_pred), test['Sale Price']) < 280000\n... else: \n...     cond = False\n>>> cond == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> if (os.path.exists('cook_county_test.csv')):\n...     test = pd.read_csv('cook_county_test.csv')\n...     cond = rmse(np.exp(Y_test_pred), test['Sale Price']) < 300000\n... else: \n...     cond = False\n>>> cond == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": [
      0.5,
      0.5,
      0.5,
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> rmse_cheap >= 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> rmse_expensive >= 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= prop_overest_cheap <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= prop_overest_expensive <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> prop_overest_interval(preds_df, 10, 14) >= 0 and prop_overest_interval(preds_df, 10, 14) <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> rmse_interval(preds_df, 10, 14) < 1000000000.0 and rmse_interval(preds_df, 10, 14) > 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
