{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"p2a.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project 2a: Predicting Housing Prices in Cook County\n",
    "\n",
    "\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for submission support.\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope. \n",
    "\n",
    "If you run into issues with pandas, jupyter notebook, etc. look at the [Debugging Guide](https://mtu.instructure.com/courses/1527249/pages/debugging-guide).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In HW 12, you performed some basic Exploratory Data Analysis (EDA), laying out the thought process that leads to certain modeling decisions. Then, you added a few new features to the dataset and cleaned the data in the process.\n",
    "\n",
    "In this project, you will specify and fit a linear model to a few features of the housing data to predict house prices. Next, we will analyze the error of the model and brainstorm ways to improve the model's performance. Finally, we'll delve deeper into the implications of predictive modeling within the Cook County Assessor's Office (CCAO) case study, especially because statistical modeling is how the CCAO valuates properties. Given the history of racial discrimination in housing policy and property taxation in Cook County, consider the impacts of your modeling results as you work through this project, and think about what fairness might mean to property owners in Cook County.\n",
    "\n",
    "After this part of the project, you should be comfortable with:\n",
    "- Implementing a data processing pipeline using `pandas`.\n",
    "- Using `scikit-learn` to build and fit linear models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Start\n",
    "\n",
    "For each question in the assignment, please write down your answer in the answer cell(s) right below the question. \n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run code, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder.** Please be sure to check your results carefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#from feature_func_hw12 import *\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training, validation, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists('cook_county_train_val.csv')):\n",
    "    with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "        item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is split into a training set, a validation set, and a test set. Importantly, the test set does not contain values for our target variable, `Sale Price`. In this project, you will train a model on the training and validation sets and then use this model to predict the `Sale Price`s of the test set. In the cell below, we load the training and validation sets into the `DataFrame` `training_val_data`.\n",
    "\n",
    "Note, we are using a sample of the full data set in order to speed-up analysis and use less memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data = pd.read_csv(\"cook_county_train_val.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the shape of the data matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 81916 observations and 62 features in training data\n",
    "assert training_val_data.shape == (81916, 62)\n",
    "# Sale Price is provided in the training/validation data\n",
    "assert 'Sale Price' in training_val_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's remind ourselves of the data available to us in the Cook County dataset. Remember, a more detailed description of each variable is included in `codebook.txt`, which is in the same directory as this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 1: Human Context and Ethics\n",
    "\n",
    "In this part of the project, we will explore the human context of our housing dataset. **You should watch the [extra video](https://youtu.be/PvxMAukFvJE?feature=shared&t=80) before attempting this question.**\n",
    "\n",
    "Note, links to the video and slides are available on Canvas for this project. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 1a\n",
    "\"How much is a house worth?\" Who might be interested in an answer to this question? **Please list at least three different parties (people or organizations) and state whether each one has an interest in seeing the housing price be low or high.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Which of the following scenarios strike you as unfair, and why? You can choose more than one. There is no single right answer, but you must explain your reasoning. Would you consider some of these scenarios more (or less) fair than others? Why?\n",
    "\n",
    "A. A homeowner whose home is assessed at a higher price than it would sell for.  \n",
    "B. A homeowner whose home is assessed at a lower price than it would sell for.  \n",
    "C. An assessment process that systematically overvalues inexpensive properties and undervalues expensive properties.  \n",
    "D. An assessment process that systematically undervalues inexpensive properties and overvalues expensive properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Consider a model that is fit to $n = 50$ training observations. We denote the response as $y$ (Log Sale Price), the prediction as $\\hat{y}$, and the corresponding residual to be $y - \\hat{y}$. Which residual plot corresponds to a model that might make property assessments that result in regressive taxation? Recall from the video that regressive taxation overvalues inexpensive properties and undervalues expensive properties. Assume that all three plots use the same vertical scale and that the horizontal line marks $y - \\hat{y} = 0$. Assign `q1c` to the string letter corresponding to your plot choice.\n",
    "\n",
    "**Hint:** When a model overvalues a property (predicts a `Sale Price` greater than the actual `Sale Price`), what are the relative sizes of $y$ and $\\hat{y}$? What about when a model undervalues a property?\n",
    "\n",
    "<img src='images/res_plots.png' width=\"900px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CCAO Dataset\n",
    "\n",
    "You'll work with the dataset from the Cook County Assessor's Office (CCAO) in Illinois. This government institution determines property taxes across most of Chicago's metropolitan areas and nearby suburbs. In the United States, all property owners must pay property taxes, which are then used to fund public services, including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models considering multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "However, this system is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing \"[racially discriminatory assessments and taxes](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html).\" The lawsuit included claims that the assessor's office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines. Wealthy homeowners, who were typically white, [paid less in property taxes](https://fix8media-chicago.squarespace.com/bpnc-v-berrios-resource-page), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, \"[The Tax Divide](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html),\" delves into how this was uncovered. After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments had been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "Make sure to watch [the video](https://youtu.be/PvxMAukFvJE?feature=shared&t=80) before answering the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 1d\n",
    "\n",
    "What were the central problems with the earlier property tax system in Cook County as reported by the Chicago Tribune? What were the primary causes of these problems? \n",
    "\n",
    "**Note:** Along with reading the paragraph above, you will need to watch [the video](https://youtu.be/PvxMAukFvJE?feature=shared&t=80)  to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 2: Preparing Data\n",
    "\n",
    "\n",
    "Let's split the dataset into a training set and a validation set. We will use the training set to fit our model's parameters and the validation set to evaluate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on **unseen data** such as the test set in `cook_county_contest_test.csv`.\n",
    "\n",
    "In the cell below, complete the function `train_val_split` that splits `data` into two smaller `DataFrame`s named `train` and `validation`. Let `train` contain 80% of the data, and let `validation` contain the remaining 20%. **You should not import any additional libraries for this question.** \n",
    "\n",
    "You should only use `NumPy` functions to generate randomness! Your answer should use the variable `shuffled_indices` defined for you. Take a look at the [documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.permutation.html) for `np.permutation` to better understand what `shuffled_indices` contains.\n",
    "\n",
    "**Hint:** While there are multiple solutions, one way is to create two `NumPy` arrays named `train_indices` and `validation_indices` (or any variable names of your choice) that contain a *random* 80% and 20% of the indices, respectively. Then, use these arrays to index into `data` to create your final `train` and `validation` `DataFrame`s. To ensure that your code matches the solution, use the first 80% as the training set and the last 20% as the validation set. Remember, the values you use to partition `data` must be integers!\n",
    "\n",
    "*The provided tests check that you not only answered correctly but ended up with the same train/validation split as our reference implementation. Testing later on is easier this way.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This makes the train-validation split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_val_split in general.\n",
    "\n",
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "def train_val_split(data):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame `data` and randomly splits it into two smaller DataFrames \n",
    "    named `train` and `validation` with 80% and 20% of the data, respectively. \n",
    "    \"\"\"\n",
    "    \n",
    "    data_len = data.shape[0]\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    ...\n",
    "    train = ...\n",
    "    validation = ...\n",
    "    return train, validation\n",
    "train, validation = train_val_split(training_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 3: Fitting a Simple Model\n",
    "\n",
    "Let's fit our linear regression model using the ordinary least squares estimator! We will start with something simple by using only two features: the **number of bedrooms** in the household and the **log-transformed total area covered by the building** (in square feet). \n",
    "\n",
    "Consider the following expression for our first linear model that contains one of the features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "In parallel, we will also consider a second model that contains both features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3a\n",
    "\n",
    "**Without running any calculation or code**, assign `q3a` to be the comparator ('>=', '=', '<=') that fills the blank in the following statement:\n",
    "\n",
    "We quantify the loss on our linear models using MSE (Mean Squared Error). Consider the training loss of the first model and the training loss of the second model. We are guaranteed that:\n",
    "\n",
    "$$\n",
    "\\text{Training Loss of the 1st Model} ~~  \\_\\_\\_\\_ ~~ \\text{Training Loss of the 2nd Model}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Pipeline Function\n",
    "\n",
    "In HW 12, you wrote a few functions that added features to the dataset. Instead of calling them manually one by one each time, it is best practice to encapsulate all of this feature engineering into one \"pipeline\" function. Defining and using a pipeline reduces all the feature engineering to just one function call and ensures that the same transformations are applied to all data.  Below, we combined some functions into a single helper function that outputs `X` and `Y` for the first model above. Try to understand what this function does! \n",
    "\n",
    "**Note 1:** We have automatically imported staff implementations of the functions you wrote in Project A1. These functions are `remove_outliers`, `add_total_bedrooms`, `find_expensive_neighborhoods`, `add_in_expensive_neighborhood`, and `ohe_roof_material`. You are welcome to copy over your own implementations if you would like.\n",
    "\n",
    "**Note 2:** The staff implementation provided for `remove_outliers` is slightly different from what you did in HW 12. Here `remove_outliers` is exclusive for the bounds whereas in HW 12, it was inclusive for the bounds. `remove_outliers` will only output values strictly greater than the lower bound and strictly smaller than the upper bound. Feel free to still use your original implementation of the function; it shouldn't affect your score if it was done correctly but may slightly change your approach to `q5f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_func_hw12 import *    # Import functions from HW 12\n",
    "\n",
    "###### Copy any function you would like to below ######\n",
    "...\n",
    "#######################################################\n",
    "\n",
    "\n",
    "def feature_engine_simple(data):\n",
    "    # Remove outliers\n",
    "    data = remove_outliers(data, 'Sale Price', lower=499)\n",
    "    # Create Log Sale Price column\n",
    "    data = log_transform(data, 'Sale Price')\n",
    "    # Create Bedroom column\n",
    "    data = add_total_bedrooms(data)\n",
    "    # Select X and Y from the full data\n",
    "    X = data[['Bedrooms']]\n",
    "    Y = data['Log Sale Price']\n",
    "    return X, Y\n",
    "\n",
    "# Reload the data\n",
    "full_data = pd.read_csv(\"cook_county_train_val.csv\")\n",
    "\n",
    "# Process the data using the pipeline for the first model.\n",
    "np.random.seed(1337)\n",
    "train_m1, valid_m1 = train_val_split(full_data)\n",
    "X_train_m1_simple, Y_train_m1_simple = feature_engine_simple(train_m1)\n",
    "X_valid_m1_simple, Y_valid_m1_simple = feature_engine_simple(valid_m1)\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m1_simple.head())\n",
    "display(Y_train_m1_simple.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.pipe`\n",
    "\n",
    "Alternatively, we can build the pipeline using `pd.DataFrame.pipe` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html)). Take a look at our use of `pd.DataFrame.pipe` below. \n",
    "\n",
    "The following function `feature_engine_pipe` takes in a `DataFrame` `data`, a list `pipeline_functions` containing 3-element tuples `(function, arguments, keyword_arguments)` that will be called on `data` in the pipeline, and the label `prediction_col` that represents the column of our target variable (`Sale Price` in this case). You can use this function with each of the tuples passed in through `pipeline_functions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to define feature_engine_pipe; no further action is needed.\n",
    "def feature_engine_pipe(data, pipeline_functions, prediction_col):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "    X = data.drop(columns=[prediction_col])\n",
    "    Y = data.loc[:, prediction_col]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3b\n",
    "\n",
    "It is time to prepare the training and validation data for the two models we proposed above. Use the following two cells to reload a fresh dataset from scratch and run them through the following preprocessing steps using `feature_engine_pipe` for each model:\n",
    "\n",
    "- Perform a `train_val_split` on the original dataset, loaded as the `DataFrame` `full_data`. Let 80% of the set be training data, and 20% of the set be validation data. \n",
    "- For both the training and validation set,\n",
    "    1. Remove outliers in `Sale Price` so that we consider households with a price that is greater than 499 dollars (or equivalently, a price that is 500 dollars or greater). \n",
    "    2. Apply log transformations to the `Sale Price` and the `Building Square Feet` columns to create two new columns, `Log Sale Price` and `Log Building Square Feet`.\n",
    "    3. Extract the total number of bedrooms into a new column `Bedrooms` from the `Description` column.\n",
    "    4. Select the columns `Log Sale Price` and `Bedrooms` (and `Log Building Square Feet` if this is the second model). We have implemented the helper function `select_columns` for you.\n",
    "    5. Return the design matrix $\\mathbb{X}$ and the observed vector $\\mathbb{Y}$. Note that $\\mathbb{Y}$ refers to the transformed `Log Sale Price`, not the original `Sale Price`. **Your design matrix and observed vector should be `NumPy` arrays or `pandas` `DataFrame`s**.\n",
    "\n",
    "Assign the final training data and validation data for both models to the following set of variables:\n",
    "\n",
    "- First Model: `X_train_m1`, `Y_train_m1`, `X_valid_m1`, `Y_valid_m1`. This is already implemented for you. \n",
    "- Second Model: `X_train_m2`, `Y_train_m2`, `X_valid_m2`, `Y_valid_m2`. Please implement this in the second cell below. You may use the first model as an example.\n",
    "\n",
    "For an example of how to work with pipelines, we have processed model 1 for you using `m1_pipelines` by passing in the corresponding pipeline functions as a list of tuples in the below cell. Your task is to do the same for model 2 in the cell after —— that is, save your pipeline functions as a list of tuples and assign it to `m2_pipelines` for model 2.\n",
    "\n",
    "As a refresher, the equations model 1 and model 2, respectively, are:\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$\n",
    "\n",
    "**Note**: Do not change the line `np.random.seed(1337)` as it ensures we are partitioning the dataset the same way for both models (otherwise, their performance isn't directly comparable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data\n",
    "full_data = pd.read_csv(\"cook_county_train_val.csv\")\n",
    "\n",
    "# Apply feature engineering to the data using the pipeline for the first model\n",
    "np.random.seed(1337)\n",
    "train_m1, valid_m1 = train_val_split(full_data)\n",
    "\n",
    "# Helper function\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "# Pipelines, a list of tuples\n",
    "m1_pipelines = [\n",
    "    (remove_outliers, None, {\n",
    "        'variable': 'Sale Price',\n",
    "        'lower': 499,\n",
    "    }),\n",
    "    (log_transform, None, {'col': 'Sale Price'}),\n",
    "    (add_total_bedrooms, None, None),\n",
    "    (select_columns, ['Log Sale Price', 'Bedrooms'], None)\n",
    "]\n",
    "\n",
    "X_train_m1, Y_train_m1 = feature_engine_pipe(train_m1, m1_pipelines, 'Log Sale Price')\n",
    "X_valid_m1, Y_valid_m1 = feature_engine_pipe(valid_m1, m1_pipelines, 'Log Sale Price')\n",
    "\n",
    "# Take a look at the result\n",
    "# It should be the same above as the result returned by feature_engine_simple\n",
    "display(X_train_m1.head())\n",
    "display(Y_train_m1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "# Process the data using the pipeline for the second model\n",
    "train_m2, valid_m2 = ...\n",
    "\n",
    "\n",
    "m2_pipelines = ...\n",
    "\n",
    "X_train_m2, Y_train_m2 = ...\n",
    "X_valid_m2, Y_valid_m2 = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m2.head())\n",
    "display(Y_train_m2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Finally, let's do some regression!\n",
    "\n",
    "We first initialize a `sklearn.linear_model.LinearRegression` object [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for both of our models. We set the `fit_intercept = True` to ensure that the linear model has a non-zero intercept (i.e., a bias term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_m1 = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_m2 = lm.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to fit our linear regression model. Use the cell below to fit both models and then use it to compute the fitted values of `Log Sale Price` over the training data and the predicted values of `Log Sale Price` for the validation data.\n",
    "\n",
    "Assign the predicted values from both of your models on the training and validation set to the following variables:\n",
    "\n",
    "- First Model: predicted values on **training set**: `Y_fitted_m1`, predicted values on **validation set**: `Y_predicted_m1`\n",
    "- Second Model: predicted values on **training set**: `Y_fitted_m2`, predicted values on **validation set**: `Y_predicted_m2`\n",
    "\n",
    "**Note**: To make sure you understand how to find the predicted value for both the training and validation data set, there won't be any hidden tests for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the 1st model\n",
    "...\n",
    "# Compute the fitted and predicted values of Log Sale Price for 1st model\n",
    "Y_fitted_m1 = ...\n",
    "Y_predicted_m1 = ...\n",
    "\n",
    "# Fit the 2nd model\n",
    "...\n",
    "# Compute the fitted and predicted values of Log Sale Price for 2nd model\n",
    "Y_fitted_m2 = ...\n",
    "Y_predicted_m2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Question 4: Evaluate Our Simple Model\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "Let's now move into the analysis of our two models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values.\n",
    "    Input:\n",
    "      predicted (1D array): Vector of predicted/fitted values\n",
    "      actual (1D array): Vector of actual values\n",
    "    Output:\n",
    "      A float, the RMSE value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 4a\n",
    "\n",
    "One way of understanding a model's performance (and appropriateness) is through a plot of the residuals versus the observations.\n",
    "\n",
    "In the cell below, use `plt.scatter` [(documentation)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) to plot the **residuals** from predicting `Log Sale Price` using **only the second model** against the original `Log Sale Price` for the **validation data**. With such a large dataset, it is difficult to avoid overplotting entirely.  This plot should have the same axis as those in Question 1c. You should also **ensure that the dot size and opacity in the scatter plot are set appropriately** to reduce the impact of overplotting as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d79f42d60b94fca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Based on the structure you see in your plot, does this model seem like it will correspond to _regressive_, _fair_, or _progressive_ taxation?\n",
    "\n",
    "Assign \"regressive\", \"fair\" or \"progressive\" to `q4b` in the cell below accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q4b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our simple model explains some of the variability in price, there is certainly still a lot of room for improvement —— one reason is we have been only utilizing 1 or 2 features (out of a total of 70+) so far! Can you engineer and incorporate more features to improve the model's fairness and accuracy? We won't be asking you to provide your answers here, but this will be important going into the next part of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Congratulate you on finishing P2a!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the Project 2a assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the Project 2a Written assignment. If you run into any issues when running this cell, feel free to check this Debugging Guide.\n",
    "\n",
    "If there are issues with automatically generating the PDF, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> PDF`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit those. \n",
    "\n",
    "**Please make sure you submit the following to the right assignments:**\n",
    "\n",
    "* **Project 2a:** Submit the zip file generated by using the `grader.export()` cell provided below.\n",
    "* **Project 2a Written:** Gradescope will automatically submit the PDF from the zip file submitted earlier. You do not need to submit anything to this assignment yourself, but *please check that the submission went through properly and that all plots rendered correctly*.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that everything was generated and submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p2a",
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1c": {
     "name": "q1c",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1c.lower() in ['a', 'b', 'c']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      1,
      2,
      2,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> train.shape == (65532, 62)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> validation.shape == (16384, 62)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(train['Sale Price'].mean(), 245739.7140786, atol=0.001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(train.index[:5], [161940, 121102, 159201, 149269, 164464])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(validation['Sale Price'].mean(), 243254.338378, atol=0.001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(validation.index[-5:], [46739, 17803, 7074, 29930, 196113])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (q3a in ['>=', '=', '<='])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": [
      2,
      2,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(X_train_m1, pd.core.frame.DataFrame) and isinstance(Y_train_m1, pd.core.series.Series) and \\\n... isinstance(X_valid_m1, pd.core.frame.DataFrame) and isinstance(Y_valid_m1, pd.core.series.Series) and \\\n... isinstance(X_train_m2, pd.core.frame.DataFrame) and isinstance(Y_train_m2, pd.core.series.Series) and \\\n... isinstance(X_valid_m2, pd.core.frame.DataFrame) and isinstance(Y_valid_m2, pd.core.series.Series)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(m2_pipelines) == 5\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> log_transform in set([p[0] for p in m2_pipelines])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": [
      1.5,
      1.5,
      1.5,
      1.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(Y_fitted_m1.max(), 15.057181454, atol=0.0001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(Y_fitted_m2.max(), 15.16885283573, atol=0.0001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(Y_predicted_m1.max(), 15.55548856869, atol=0.0001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(Y_predicted_m2.max(), 14.9296658973, atol=0.0001)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q4b.lower() in ['regressive', 'fair', 'progressive']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
