{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 5: Data Cleaning and DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To receive credit for a lab, answer all questions correctly and submit before the deadline.\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline. We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline. This way, you will have ample time to contact staff for submission support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "\n",
    "## Part 1: Tricky Pandas\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Sometimes, `pandas` give you weird output that you may not expect.  The next series of question walks you through a few examples that might surprise you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Question 1a\n",
    "\n",
    "For this question, you will define a function, `trick_1a` that returns a number that is the answer to a multiple-choice question.  You may need to experiment with DataFrames to arrive at your answers. \n",
    "\n",
    "The function `trick_1a` should not take any arguments. In the function you will: \n",
    "\n",
    "* Create a DataFrame named `trick1A` that has three columns labeled `Name`, `Name`, and `Age`. `trick1A` should have 3 rows of any values (this is up to you).\n",
    "  \n",
    "* Save the DataFrame `trick1A` to a `.csv` file called `trick1A.csv` without the index.\n",
    "\n",
    "* Create another DataFrame, named `trick1B`, by reading in the file `trick1A.csv`.\n",
    "\n",
    "Your function should return `1`, `2`, or `3` by observing the following. \n",
    "\n",
    "1. It was not possible to create a DataFrame with duplicate columns.\n",
    "2. `trickA` and `trickB` have the same column names.\n",
    "3. `trickA` and `trickB` have different column names.\n",
    "\n",
    "Note, your function should only have three lines of code and use only the following parts of `pandas`: \n",
    "* [DataFrame constructor](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame)\n",
    "* [`to_csv` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv)\n",
    "* [`read_csv` function](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trick_1a(): \n",
    "    # Construct DataFrame tricky1A\n",
    "    tricky1A = pd.DataFrame(...)\n",
    "    # Save the DataFrame tricky1A to a file tricky1A.csv \n",
    "    ...\n",
    "    # Create DataFrame tricky1B by reading in file tricky1A.csv\n",
    "    tricky1B = ...\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 1b\n",
    "\n",
    "For this question, you will define a function, `trick_1b` that is to do the same task as the function description in Question 1a. \n",
    "\n",
    "Now, your function can still use the following parts of `pandas`: \n",
    "\n",
    "* [DataFrame constructor](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame),\n",
    "* [`to_csv` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv), and\n",
    "* [`read_csv` function](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv)\n",
    "\n",
    "But, it can also use other methods and functions after the constructor, e.g., \n",
    "* ['rename' method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trick_1b(): \n",
    "    # Construct DataFrame tricky1A\n",
    "    tricky1A = pd.DataFrame(...)\n",
    "    # Save the DataFrame tricky1A to a file tricky1A.csv \n",
    "    ...\n",
    "    # Create DataFrame tricky1B by reading in file tricky1A.csv\n",
    "    tricky1B = ...\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "#### Question 1c \n",
    "\n",
    "Create a function `trick_1c` that does not take any arguments. \n",
    "\n",
    "Use the cell below to experiment with the following: \n",
    "\n",
    "* Create a DataFrame named `bools` that has four columns: `True`, `True`, `False`, `False`. Each column name should be Boolean.\n",
    "* `bools` should have 4 rows; the values are up to you.\n",
    "* Predict the shape of the DataFrame that results by running each of the three lines of code below. Pick a corresponding answer from the given list. Your function should return a list with three numbers, one for each line.\n",
    "* You should be able to answer without running any code, but feel free to run code to check your answer.\n",
    "\n",
    "```python\n",
    "bools[True]\n",
    "bools[[True, True, False, False]]\n",
    "bools[[True, False]]\n",
    "```\n",
    "\n",
    "Answer choices:\n",
    "1. DataFrame: 2 columns, 1 row\n",
    "2. DataFrame: 2 columns, 2 rows\n",
    "3. DataFrame: 2 columns, 3 rows\n",
    "4. DataFrame: 2 columns, 4 rows\n",
    "5. DataFrame: 3 columns, 1 rows\n",
    "6. DataFrame: 3 columns, 2 rows\n",
    "7. DataFrame: 3 columns, 3 rows\n",
    "8. DataFrame: 3 columns, 4 rows\n",
    "9. DataFrame: 4 columns, 1 rows\n",
    "10. DataFrame: 4 columns, 2 rows\n",
    "11. DataFrame: 4 columns, 3 rows\n",
    "12. DataFrame: 4 columns, 4 rows\n",
    "13. Error\n",
    "\n",
    "**Hints:** It's recommended to refer to the pd.DataFrame documentation for information on the parameters `data` and `columns`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell to experiment with \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trick_1c(): \n",
    "    # Return a list with three numbers, one for answer for each line.\n",
    "    return None\n",
    "trick_ans = trick_1c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Part 2: Summary Statistics \n",
    "\n",
    "In this question you will define two general purpose functions that make it easy to qualitatively assess the contents of a DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Complete the implementation of the function `population_stats`, which takes in a DataFrame `df` and returns a DataFrame indexed by the columns of `df`, with the following columns:\n",
    "* `'num_nonnull'`, which contains the number of non-null entries in each column.\n",
    "* `'prop_nonnull'`, which contains the proportion of entries in each column that are non-null.\n",
    "* `'num_distinct'`, which contains the number of distinct non-null entries in each column.\n",
    "* `'prop_distinct'`, which contains the proportion of non-null entries that are distinct in each column.\n",
    "       \n",
    "For example, if `df` has a column named `'ages'` with the following elements (note that `np.NaN` is a null value):\n",
    "       \n",
    "```py\n",
    "[2, 2, 2, np.NaN, 5, 7, 5, 10, 11, np.NaN]\n",
    "```\n",
    "\n",
    "Then:\n",
    "- `'num_nonnull'` is 8, and `'prop_nonnull'` is $\\frac{8}{10}$ = 0.8.\n",
    "- There are six distinct entries, `[2, 5, 7, 10, 11, np.NaN]`, but only 5 of them are non-null. So the number of distinct non-null entries, `'num_distinct'`, is 5.\n",
    "- There are 5 distinct non-null entries, and there are 8 total non-null entries, so `'prop_distinct'` is $\\frac{5}{8}$ = 0.625.\n",
    "\n",
    "Putting it all together, `population_stats(df).loc['ages']` should be a Series containing the numbers 8, 0.8, 5, and 0.625.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "You should not use a for-loop to answer this question. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def population_stats(df): \n",
    "    # Returns a DataFrame indexed by the columns of `df`, with the following columns:\n",
    "    #  'num_nonnull', the number of non-null entries in each column.\n",
    "    #  'prop_nonnull', the proportion of entries in each column that are non-null.\n",
    "    #  'num_distinct', the number of distinct, non-null entries in each column.\n",
    "    #  'prop_distinct', the proportion of distinct, non-null entries in each column.\n",
    "\n",
    "    ...\n",
    "    return df\n",
    "    \n",
    "pop_data = np.random.choice(range(10), size=(100, 4))\n",
    "df_pop = pd.DataFrame(pop_data, columns = 'A B C D'.split())\n",
    "out_pop = population_stats(df_pop)\n",
    "out_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't change this cell \n",
    "df_pop2 = pd.DataFrame({'A': [2, 2, 2, np.NaN, 5, 7, 5, 10, 11, np.NaN]})\n",
    "out_pop2 = population_stats(df_pop2)\n",
    "out_pop2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Complete the implementation of the function `most_common`, which takes in a DataFrame `df` and a number `N` and returns a DataFrame of the `N` most-common values and their counts for each column of `df`. Any column with fewer than `N` distinct values should contain `np.NaN` in those entries.\n",
    "\n",
    "For example, consider the DataFrame shown on the left. This DataFrame is a subset of `salaries`, a larger DataFrame containing information on employees in the City of San Diego. The subset below contains two of the original columns: `'Job Title'` which contains job titles for employees, and `'status'` which denotes whether the employee works a full time position (`'FT'`) or a part time position (`'PT'`). On the right, the return value of `most_common(salaries, N=5)` is shown.\n",
    "\n",
    "You can assume that there are no ties in our hidden tests.\n",
    "\n",
    "<table><tr>\n",
    "    <td><img src=\"data/imgs/dataframe.png\" width=\"80%\"/></td>\n",
    "    <td><img src=\"data/imgs/most_common.png\" width=\"80%\"/></td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "***Hint***: You may find that initializing an empty DataFrame with `N` rows and adding columns to it is useful in your implementation.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>Remember, the only question in this lab that you're allowed to use a loop in is Question 3 – that's this question.</b> Here, you may use a <code>for</code>-loop to loop over the columns in the input DataFrame (<code>df</code>), but not the rows. <b>If you use a <code>for</code>-loop or <code>while</code>-loop in any other question, you may lose points!</b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_common(df, N=5): \n",
    "    # Returns a DataFrame of the N most common values and their counts \n",
    "    #   for each column of the DataFrame df\n",
    "\n",
    "    ...\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't change this cell \n",
    "common_data = np.random.choice(range(10), size=(100, 2))\n",
    "common_df = pd.DataFrame(common_data, columns='A B'.split())\n",
    "common_out = most_common(common_df, N=3)\n",
    "common_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Part 3: Superheroes  \n",
    "\n",
    "The questions below analyze a dataset of superheroes found in the `data` directory. One of the datasets lists the attributes of each superhero, while the other is a *Boolean* DataFrame describing which superheroes have which superpowers. Note, the datasets contain information on both **good** superheroes, as well as **bad** superheroes (AKA villains).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4\n",
    "\n",
    "\n",
    "Let's start working with the `powers` dataset, which you can see in `data/superheroes_powers.csv`. \n",
    "\n",
    "Complete the implementation of the function `super_hero_powers`, which takes in a DataFrame like `powers` and returns a list with the following three entries:\n",
    "\n",
    "1. The name of the superhero with the greatest number of superpowers.\n",
    "2. The name of the second most common superpower among superheroes who can fly (the most common being `'Flight'` itself).\n",
    "3. The name of the most common superpower among superheroes with only one superpower.\n",
    "\n",
    "You should **not** be hard-coding your answers in this question; your function should work on any DataFrame similar to `powers`. In each case, you can assume the answer is unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def super_hero_powers(df): \n",
    "    # Returns a list with the following entries: \n",
    "    #  - name of superhero with the greatest number of superpowers \n",
    "    #  - name of the second most common superpower among superheros that fly\n",
    "    #  - name of most common superpower among superheroes with only one superpower\n",
    "\n",
    "    ...\n",
    "    return None\n",
    "    \n",
    "\n",
    "super_fp = Path('data') / 'superheroes_powers.csv'\n",
    "powers = pd.read_csv(super_fp)\n",
    "super_out = super_hero_powers(powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "### Question 5\n",
    "\n",
    "You will use the dataset in `data/superheroes.csv` as a DataFrame. Your function `population_stats` from Question 2 will be called on the DataFrame. You should notice that there are very few actually null (`np.NaN`) values, but there are many entries that **should** be null, because they're missing.\n",
    "\n",
    "Complete the implementation of the function `clean_heroes`, which takes in a DataFrame like the one created from `superheroes.csv` and returns a new DataFrame with all of the missing values replaced with `np.NaN`.\n",
    "\n",
    "After cleaning the superheroes dataset with `clean_heroes`, you will run `population_stats` on it again. As a result of the cleaning, population_stats should show that there are more null values.\n",
    "\n",
    "***Note***: Most of the work in this question is identifying how the missing values are stored in the DataFrame. The implementation of the function should only take one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_heroes(df): \n",
    "    # Returns a DataFrame with all the missing values replaced with np.NaN \n",
    "\n",
    "    ...\n",
    "    return None\n",
    "    \n",
    "\n",
    "superheroes_fp = Path('data') / 'superheroes.csv'\n",
    "heroes = pd.read_csv(superheroes_fp, index_col=0)\n",
    "print(population_stats(heroes))\n",
    "\n",
    "clean_out = clean_heroes(heroes)\n",
    "print(population_stats(clean_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 6\n",
    "\n",
    "Using the **cleaned** superhero data, `clean_out`, we will now generate some insights in the following questions. \n",
    "\n",
    "For each subquestion other than Question 6c and 6d, you should generate the answer using `pandas` methods and functions. \n",
    "For Question 6c and 6d, you can use your `pandas` knowledge to determine the information to answer the question, but you can hard-code in your final response. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 6a\n",
    "\n",
    "What is the name of the tallest `'Mutant'` with `'No Hair'`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tallest_no_hair = ...\n",
    "    \n",
    "tallest_no_hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 6b\n",
    "\n",
    "Among the publishers who have more than 5 characters, which publisher has the highest proportion of human characters? If there is a tie, return the publisher whose name is first alphabetically. We define a character to be human if their `'Race'` is exactly the string `'Human'`; for instance, a `'Race'` of `'Human / Radiation'` is non-human for the purposes of this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-pandas-boxplot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "...\n",
    "publisher_prop_human = ...\n",
    "    \n",
    "publisher_prop_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 6c \n",
    "\n",
    "Among the characters whose `'Height'`s we know, who is taller on average – `'good'` characters or `'bad'` characters?\n",
    "\n",
    "Use your `pandas` knowledge to determine the information to answer the question, but you can hard-code in your final response. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "taller_chars = ...\n",
    "taller_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 6d \n",
    "\n",
    "Which publisher has a greater proportion of `'bad'` characters – `'Marvel Comics'` or `'DC Comics'`?\n",
    "\n",
    "Use your `pandas` knowledge to determine the information to answer the question, but you can hard-code in your final response. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "publish_more_bad = ...\n",
    "publish_more_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 6e \n",
    "\n",
    "There is only one character that is **both** more than one standard deviation above the mean in height and more than one standard deviation below the mean in weight.  What is their name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "tall_and_light = ...\n",
    "tall_and_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "#### Question 6f \n",
    "\n",
    "Which `'Publisher'` that isn't `'Marvel Comics'` or `'DC Comics'` has the most characters? Consider all characters whose `'Publisher'` we know – that is, don't drop rows because they have null values in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "most_chars = ...\n",
    "most_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br><br>\n",
    "\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "## Congratulations! You have finished Lab 05!\n",
    "\n",
    "\n",
    "Congrats! You are finished with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: To make sure the test cases run correctly, click `Kernel>Restart & Run All` and make sure all of the test cases are still passing. Doing so will submit your code for you. \n",
    "\n",
    "If your test cases are no longer passing after restarting, it's likely because you're missing a variable, or the modifications that you'd previously made to your DataFrame are no longer taking place (perhaps because you deleted a cell). \n",
    "\n",
    "You may submit this assignment as many times as you'd like before the deadline.\n",
    "\n",
    "**You must restart and run all cells before submitting. Otherwise, you may pass test cases locally, but not on our servers. We will not entertain regrade requests of the form, “my code passed all of my local test cases, but failed the autograder”.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "history": [
   {
    "code": "from IPython.display import YouTubeVideo\nYouTubeVideo(\"4DxhlTyVBHA\")",
    "id": "9e1cf82045d44740bb43e7687df1ae18",
    "idx": 3,
    "time": "2021-02-11T21:47:57.531Z",
    "type": "execution"
   },
   {
    "id": "9e1cf82045d44740bb43e7687df1ae18",
    "time": "2021-02-11T21:47:58.106Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab05",
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": [
      1,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ans = trick_1a()\n>>> ans == 1 or ans == 2 or ans == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> trick_1a() == 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ans = trick_1b()\n>>> ans == 1 or ans == 2 or ans == 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(trick_ans, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(trick_ans[1], int)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      1,
      1,
      1,
      1,
      1,
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_pop.index.tolist() == ['A', 'B', 'C', 'D']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out_pop.columns.tolist() == ['num_nonnull', 'prop_nonnull', 'num_distinct', 'prop_distinct']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (out_pop['num_distinct'] <= 10).all()\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (out_pop['prop_nonnull'] == 1.0).all()\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out_pop2.index.tolist() == ['A']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out_pop2.columns.tolist() == ['num_nonnull', 'prop_nonnull', 'num_distinct', 'prop_distinct']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(out_pop2.iloc[0] == [8.0, 0.8, 5.0, 0.625])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> common_out.index.tolist() == [0, 1, 2]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> common_out.columns.tolist() == ['A_values', 'A_counts', 'B_values', 'B_counts']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> common_out['A_values'].isin(range(10)).all()\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> common_out['B_values'].isin(range(10)).all()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": [
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(super_out, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(super_out) == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([isinstance(x, str) for x in super_out])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": [
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> sum(clean_out['Skin color'].isnull()) > sum(heroes['Skin color'].isnull())\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> sum(clean_out['Weight'].isnull()) > sum(heroes['Weight'].isnull())\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(tallest_no_hair, str)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": [
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(publisher_prop_human, str)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> publisher_prop_human in ['Dark Horse Comics', 'DC Comics', 'George Lucas', 'Marvel Comics', 'Star Trek']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> taller_chars in ['good', 'bad']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6d": {
     "name": "q6d",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(publish_more_bad, str)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> publish_more_bad in ['Marvel Comics', 'DC Comics']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6e": {
     "name": "q6e",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(tall_and_light, str)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6f": {
     "name": "q6f",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(most_chars, str)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> most_chars not in ['Marvel Comics', 'DC Comics']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
