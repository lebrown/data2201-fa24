{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb483a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb787391",
   "metadata": {},
   "source": [
    "# Lab 6 - Missing Values and Imputation \n",
    "\n",
    "To receive credit for a lab, answer all questions correctly and submit before the deadline.\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline. We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline. This way, you will have ample time to contact staff for submission support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2229be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb41aea",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "\n",
    "## Part 1: Missingness Mechanisms\n",
    "\n",
    "First, let's recap the different mechanisms of missingness we studied in lecture.\n",
    "\n",
    "#### Missing by Design (MD)\n",
    "- The missing field is deliberately missing. The missing field is deliberately set to null or not collected (hence, \"missing by design\").\n",
    "- The missingness can be exactly predicted when a column will be null, with only knowledge of the other columns using a function of the rows of the dataset.\n",
    "\n",
    "#### Missing Completely at Random (MCAR)\n",
    "- The missingness of missing value isn't related to the actual, unreported value itself, nor the values in any other fields. The missingness is not systematic.\n",
    "- The missingness is unconditionally uniform across rows. MCAR doesn't bias the observed data.\n",
    "- There is no relationship between the missing data and the any of the other data, observed or missing.\n",
    "\n",
    "#### Missing at Random (MAR)\n",
    "- The missingness of the missing value has nothing to do with the value itself, but may be related to another field.\n",
    "- The missingness is uniform across rows, perhaps conditional on another column. MAR biases the observed data, but is fixable.\n",
    "- There is a systematic relationship between the missing values and the observed data (but not the missing values themselves).\n",
    "- Difference between MD and MAR: If you can *exactly/always* determine missingness using the other columns, the missingness is MD. If there is just some sort of systematic relationship between the missing columns/values and other columns/values that may help us predict missingness, the missingness is MAR.\n",
    "\n",
    "#### Not Missing At Random (NMAR)\n",
    "- The missingness of the missing value is related to the actual, unreported value.\n",
    "- NMAR biases the observed data in unobservable ways.\n",
    "- There is relationship between the propensity of a value to be missing and its value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831c486",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 1\n",
    "\n",
    "You run a small e-commerce website and send surveys out to customers after they purchase an item from your store. The survey asks whether the customer is satisfied with their purchase (\"Yes\" or \"No\"). Below, you are presented with possible datasets, each of which contains a column `'satisfied'` as described above, as well as a `'customer_id'` number corresponding to the customer and an `'item'` column describing the item that the customer purchased. **The column `'satisfied'` is missing data.**\n",
    "\n",
    "For each of the following datasets, label the column `'satisfied'` as being `'MD'`, `'MCAR'`, `'MAR'`, or `'NMAR'`.\n",
    "\n",
    "1. The dataset consists only of the columns `'customer_id'` and `'satisfied'`.\n",
    "2. The dataset contains the `'customer_id'` of every customer with an account, even if they didn't make a purchase. Also, in this case, you notice everyone who was sent a survey filled it out.\n",
    "3. The dataset contains a column specifying if the user later returned the item.\n",
    "4. The dataset contains a column with the serial number for the item purchased.\n",
    "5. The dataset contains a column with the price of the item purchased.\n",
    "\n",
    "Complete the implementation of the function `after_purchase`, which records your answers and returns a list of length 5, containing the values `'MD'`, `'MCAR'`, `'MAR'`, or `'NMAR'`. For some questions there may be multiple good answers, but there is generally one answer that is \"best\". \n",
    "\n",
    "***Disclaimer***: It is possible to just look at the some of the correct answers by running `grader.check`. This is not a good idea – you should really think about all of the questions here, since similar questions will be on the exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4808424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def after_purchase(): \n",
    "    # Return a list with the type of missingness for the 5 datasets.\n",
    "    #  Types are 'MD', 'MCAR', 'MAR', 'NMAR'\n",
    "    \n",
    "    return None\n",
    "q1_ans = after_purchase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede4797",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ec10a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "\n",
    "## Part 2: Assessing Missingness through data \n",
    "\n",
    "Let's now focus on deciding whether data in a particular column look MCAR or MAR through permuatation tests. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e62b8",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "--- \n",
    "\n",
    "### Question 2 \n",
    "\n",
    "In the file `data/missing_heights.csv` are the heights of adult children and their fathers (`'child'` and `'father'`). The additional `'child_X'` columns are missing values in varying proportions; for each X, `'child_X'` is X\\% not missing (and hence (100-X)\\% missing). **The missingness of these `'child_X'` columns were created as MAR dependent on father's heights (similar to what was done in Lecture 10-11. The missingness of these `'child_X'` columns are all equally dependent on father's heights.**\n",
    "\n",
    "You will attempt to **verify** the missingness of the `'child_X'` columns as being dependent on the `'father'` column by using permutation tests. Your permutation tests should use the Kolmogorov-Smirnov test statistic. You can use `scipy.stats`' built-in K-S function to run your permutation tests and compute your p-values; you don't need to simulate manually using a `for`-loop, instead you can directly use `.pvalue` attribute after calling **k2_samp**.\n",
    "\n",
    "To do this, complete the implementation of the function `verify_child`, which takes in the `heights` DataFrame and returns a Series of p-values from your permutation tests, indexed by the names of the columns in `heights` that are formatted like `'child_X'` (that is, its index should be `'child_95'`, `'child_90'`, ..., `'child_5'`; the order of the Series is not important).\n",
    "\n",
    "To clarify, for each `child_X` column, you will be running one permutation test comparing it to the `father` column. Your permutation tests should run within your `verify_child` function. You can **only** use a for-loop to loop over the **columns** of `heights`, and you shouldn't need to use a `for`-loop to conduct your permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1601f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify_child(heights): \n",
    "    # Return a Series of p-values from the permutation tests\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40627a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't change this cell \n",
    "heights = pd.read_csv(Path('data') / 'missing_heights.csv')\n",
    "q2_out = verify_child(heights.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621fc51",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c8c48",
   "metadata": {},
   "source": [
    "Let's reflect on the p-values that you found: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c76d31",
   "metadata": {},
   "source": [
    "Remember, **in all seven columns, the data are truly MAR** – we know this for a fact since we were told in the question:\n",
    "\n",
    "> The missingness of these <code>'child_X'</code> columns were created as MAR dependent on father's heights (similar to what was done in Lecture 11. The missingness of these <code>'child_X'</code> columns are all equally dependent on father's heights.\n",
    "\n",
    "- If our permutation test returned a small $p$-value for a particular column, it means that the distribution of father's heights in rows where the child's height was missing looked significantly different than the distribution of father's heights in rows where the child's height was present. That's evidence that the missingness of that column depends on father's heights.\n",
    "\n",
    "- If our permutation test returned a large $p$-value for a particular column, that's evidence that the missingness of that column doesn't depend on father's heights.\n",
    "\n",
    "Despite the fact that the missingness of each `'child_X'` column truly depends on father's heights (by design), it appears that **in all cases except `'child_50'`, we'd conclude that the child's height columns are MCAR** at the 5% significance level! We should be precise – we cannot **prove** that heights are MCAR or MAR, just like we cannot prove either hypothesis in a hypothesis test. Instead, all we can say, for instance, is that two samples don't look like they were drawn from the same population distribution, and hence, the missingness of a particular column **appears** to be dependent on another column.\n",
    "\n",
    "One thing you'll notice is that when a column contains relatively few missing values, it is exceedingly difficult to conclude that values in that column are missing at random dependent on another column. Think about why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac2ec5",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #8a8c8c;\" />\n",
    "<hr style=\"border: 1px solid #ffcd00;\" />\n",
    "\n",
    "\n",
    "## Part 3: Imputation\n",
    "\n",
    "Now that we have worked with missingness mechanisms and how to detect them in data, let's focus on filling in missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d22fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3\n",
    "\n",
    "In Lecture 11, you learned how to perform single-valued imputation conditionally on a **categorical** column: impute with the mean for each group. That is, for each distinct value of the **categorical** column, there is a single imputed value.\n",
    "\n",
    "Here, you will perform single-valued imputation by conditioning on a **quantitative** column. \n",
    "\n",
    "You will work with a version of the `heights` DataFrame, `new_heights`, that has a `'father'` column and a single `'child'` column. The `'child'` column has missing values. To impute the `'child'` column, transform the `'father'` column into a categorical column by binning the values of `'father'` into [quartiles](https://en.wikipedia.org/wiki/Quartile). Once this is done, you can impute `'child'` as in lecture (and described above).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `cond_single_imputation`\n",
    "\n",
    "Complete the implementation of the function `cond_single_imputation`, which takes in a DataFrame with columns `'father'` and `'child'` (where `'child'` has missing values) and performs a single-valued mean imputation of the `'child'` column, conditional on `'father'`. Your function should return a **Series**.\n",
    "\n",
    "***Hints***:\n",
    "- `pd.qcut` may be helpful !\n",
    "- The `transform` method is useful for this question, though it's also possible to do this using the `aggregate` method.\n",
    "- As a reminder, *loops are not allowed*, and functions mentioned in \"Hints\" are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db22ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cond_single_imputation(df):\n",
    "    # Input a DataFrame with columns 'father' and 'child' (with some missing \n",
    "    #   values in child) \n",
    "    # Return a Series performing a single-valued mean imputation of the 'child' \n",
    "    #   column, conditional on 'father'\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ceb70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "new_heights = pd.read_csv(heights_fp)[['father', 'child_50']]\n",
    "new_heights = new_heights.rename(columns={'child_50': 'child'})\n",
    "q3_out = cond_single_imputation(new_heights.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63965e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "heights_q3 = pd.read_csv(heights_fp)\n",
    "heights_q3['child'] = heights_q3['child_50']\n",
    "inp_q3 = heights_q3\n",
    "out_q3 = cond_single_imputation(inp_q3)\n",
    "df_q3 = inp_q3.copy()\n",
    "df_q3['imputed'] = out_q3\n",
    "gp1_q3 = df_q3.groupby('father')['imputed'].mean()\n",
    "gp2_q3 = df_q3.groupby('father')['child'].mean()\n",
    "m_q3 = (pd.concat([gp1_q3, gp2_q3], axis=1)\n",
    "     .dropna().diff(axis=1).abs().iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfaf47",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc4ca1e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 4\n",
    "\n",
    "In Lecture 11, you learned how to impute a quantitative column by sampling from the observed values. **One problem with this technique is that the imputation will never generate imputed values that weren't already in the dataset.** For example, 57, 57.5, and 59 are values in the `'child'` column of `new_heights` while 58 is not. Thus, any imputation done by sampling from the observed values in the `'child'` column will not be able to generate a height of 58, even though it's clearly a reasonable value to occur in the dataset.\n",
    "\n",
    "To keep things simple, you will impute the `'child'` column **unconditionally** from the distribution of `'child'` heights present in the dataset. This means that you will use the values present in `'child'` to impute missing values, without looking at other columns.\n",
    "\n",
    "An approach to quantitative imputation that overcomes the limitation mentioned above is as follows:\n",
    "- Create a histogram of observed `'child'` heights, using 10 bins.\n",
    "    - Note that in your process, you don't actually need to draw a histogram – instead, use `np.histogram`.\n",
    "- Use the histogram to generate a number within the observed range of `'child'` heights:\n",
    "    - The likelihood a generated number belongs to a given bin is equal to the area of that bin. (Remember, in histograms, areas are proportions.)\n",
    "    - Any number within a fixed bin is equally likely to occur.\n",
    "    \n",
    "Let's illustrate this approach with an example. Let `demo` be the array of 10 numbers defined below.\n",
    "\n",
    "```py\n",
    "demo = np.array([10, 11, 11, 13, 14, 14, 13.5, 14, 15, 16])\n",
    "```\n",
    "\n",
    "- The first step is creating a histogram of `demo`. Note that with this small dataset, we will use 3 bins, but you will be using 10 bins in your imputation process.\n",
    "\n",
    "<img src='imgs/demo_histogram.png' width=300>\n",
    "\n",
    "- In the histogram above, we see that $2 \\cdot 0.15 = 0.3 = 30\\%$ of values lie in the [10, 12) bin, $2 \\cdot 0.1 = 0.2 = 20\\%$ of values lie in the [12, 14) bin, and $2 \\cdot 0.25 = 0.5 = 50\\%$ of values lie in the [14, 16] bin.\n",
    "- Next, we need to pick a bin at random. There's a 30\\% chance we pick the [10, 12) bin, a 20\\% chance we pick the [12, 14) bin, and a 50\\% chance we pick the [14, 16] bin. `np.random.choice` will be helpful in picking a bin at random.\n",
    "- Once we pick a bin, we pick a number **uniformly at random** from within the bin. For instance, suppose we randomly chose the [14, 16] bin in the previous step. We then must select a (real) number between 14 and 16 uniformly at random. `np.random.uniform` can help you here.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `quantitative_distribution`\n",
    "    \n",
    "Complete the implementation of the function `quantitative_distribution`, which takes in a Series, `child`, in which some values are missing, and a positive integer `N`, and returns an **array** of `N` imputed values using the method described above. \n",
    "\n",
    "***Note***: You may use a `for`-loop.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `impute_height_quant`\n",
    "\n",
    "Complete the implementation of the function `impute_height_quant`, which takes in a Series, `child`, in which some values are missing and imputes them using the scheme above. `impute_height_quant` should return a Series that is the same length of `child` but with no missing values. **You should use `quantitative_distribution` to help you do this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40849e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantitative_distribution(child, N):\n",
    "    # Input: Series, child and a positive integer N \n",
    "    # Return: an array of N imputed values \n",
    "    ...\n",
    "\n",
    "\n",
    "def impute_height_quant(child):\n",
    "    # Input: Series, child with some missing variables\n",
    "    # Return: Series of same length as child with missing values imputed. \n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fca442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "heights = pd.read_csv(heights_fp)\n",
    "child = heights['child_50']\n",
    "q4_quantitative_distribution_out = quantitative_distribution(child.copy(), 100)\n",
    "q4_impute_height_quant_out = impute_height_quant(child.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a905b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbd259",
   "metadata": {},
   "source": [
    "## Congrats! You have finished Lab 06! \n",
    "\n",
    "**Important**: To make sure the test cases run correctly, click `Kernel>Restart & Run All` and make sure all of the test cases are still passing. \n",
    "\n",
    "If your test cases are no longer passing after restarting, it's likely because you're missing a variable, or the modifications that you'd previously made to your DataFrame are no longer taking place (perhaps because you deleted a cell). \n",
    "\n",
    "You may submit this assignment as many times as you'd like before the deadline.\n",
    "\n",
    "**You must restart and run all cells before submitting. Otherwise, you may pass test cases locally, but not on our servers. We will not entertain regrade requests of the form, “my code passed all of my local test cases, but failed the autograder”.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0933378",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb5825",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8442e97",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data1202] *",
   "language": "python",
   "name": "conda-env-data1202-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab06",
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q1_ans) == 5\nTrue",
         "failure_message": "Output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q1_ans) <= set(['MD', 'MCAR', 'MAR', 'NMAR'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[0] == 'NMAR'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[0] in ['NMAR', 'MCAR']\nTrue",
         "failure_message": "dataset 1 partial credit",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[1] == 'MD'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[1] in ['MD', 'MAR']\nTrue",
         "failure_message": "dataset 2 partial credit",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[2] in ['NMAR', 'MAR']\nTrue",
         "failure_message": "dataset 3 partial credit",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[3] in ['NMAR', 'MAR', 'MCAR']\nTrue",
         "failure_message": "dataset 4 partial credit",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_ans[4] in ['MAR', 'NMAR', 'MCAR']\nTrue",
         "failure_message": "dataset 5 partial credit",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      1,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(q2_out) == pd.core.series.Series\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(q2_out) == 7\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q2_out['child_50'] < q2_out['child_95']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q2_out['child_5'] > q2_out['child_50']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      1,
      2,
      3,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_out.isna().sum() == 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> new_heights['child'].std() - q3_out.std() > 0.5\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(q3_out.mean(), inp_q3['child'].mean(), atol=0.2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose(m_q3, 0, atol=2))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": [
      1,
      1,
      2,
      2,
      1,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q4_quantitative_distribution_out.min() >= 56\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q4_quantitative_distribution_out.max() <= 79\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(q4_quantitative_distribution_out.mean(), child.mean(), atol=1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q4_impute_height_quant_out.isna().sum() == 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(q4_impute_height_quant_out.mean(), child.mean(), atol=0.5)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (set(q4_quantitative_distribution_out) - set(child.dropna())) != {}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (set(q4_impute_height_quant_out) - set(child.dropna())) != {}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
